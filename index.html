
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>Stairs documentation</title>

    <style>
      .highlight table td { padding: 5px; }
.highlight table pre { margin: 0; }
.highlight .gh {
  color: #999999;
}
.highlight .sr {
  color: #f6aa11;
}
.highlight .go {
  color: #888888;
}
.highlight .gp {
  color: #555555;
}
.highlight .gs {
}
.highlight .gu {
  color: #aaaaaa;
}
.highlight .nb {
  color: #f6aa11;
}
.highlight .cm {
  color: #75715e;
}
.highlight .cp {
  color: #75715e;
}
.highlight .c1 {
  color: #75715e;
}
.highlight .cs {
  color: #75715e;
}
.highlight .c, .highlight .cd {
  color: #75715e;
}
.highlight .err {
  color: #960050;
}
.highlight .gr {
  color: #960050;
}
.highlight .gt {
  color: #960050;
}
.highlight .gd {
  color: #49483e;
}
.highlight .gi {
  color: #49483e;
}
.highlight .ge {
  color: #49483e;
}
.highlight .kc {
  color: #66d9ef;
}
.highlight .kd {
  color: #66d9ef;
}
.highlight .kr {
  color: #66d9ef;
}
.highlight .no {
  color: #66d9ef;
}
.highlight .kt {
  color: #66d9ef;
}
.highlight .mf {
  color: #ae81ff;
}
.highlight .mh {
  color: #ae81ff;
}
.highlight .il {
  color: #ae81ff;
}
.highlight .mi {
  color: #ae81ff;
}
.highlight .mo {
  color: #ae81ff;
}
.highlight .m, .highlight .mb, .highlight .mx {
  color: #ae81ff;
}
.highlight .sc {
  color: #ae81ff;
}
.highlight .se {
  color: #ae81ff;
}
.highlight .ss {
  color: #ae81ff;
}
.highlight .sd {
  color: #e6db74;
}
.highlight .s2 {
  color: #e6db74;
}
.highlight .sb {
  color: #e6db74;
}
.highlight .sh {
  color: #e6db74;
}
.highlight .si {
  color: #e6db74;
}
.highlight .sx {
  color: #e6db74;
}
.highlight .s1 {
  color: #e6db74;
}
.highlight .s {
  color: #e6db74;
}
.highlight .na {
  color: #a6e22e;
}
.highlight .nc {
  color: #a6e22e;
}
.highlight .nd {
  color: #a6e22e;
}
.highlight .ne {
  color: #a6e22e;
}
.highlight .nf {
  color: #a6e22e;
}
.highlight .vc {
  color: #ffffff;
}
.highlight .nn {
  color: #ffffff;
}
.highlight .nl {
  color: #ffffff;
}
.highlight .ni {
  color: #ffffff;
}
.highlight .bp {
  color: #ffffff;
}
.highlight .vg {
  color: #ffffff;
}
.highlight .vi {
  color: #ffffff;
}
.highlight .nv {
  color: #ffffff;
}
.highlight .w {
  color: #ffffff;
}
.highlight {
  color: #ffffff;
}
.highlight .n, .highlight .py, .highlight .nx {
  color: #ffffff;
}
.highlight .ow {
  color: #f92672;
}
.highlight .nt {
  color: #f92672;
}
.highlight .k, .highlight .kv {
  color: #f92672;
}
.highlight .kn {
  color: #f92672;
}
.highlight .kp {
  color: #f92672;
}
.highlight .o {
  color: #f92672;
}
    </style>
    <link href="stylesheets/screen.css" rel="stylesheet" media="screen" />
    <link href="stylesheets/print.css" rel="stylesheet" media="print" />
      <script src="javascripts/all.js"></script>
  </head>

  <body class="index" data-languages="[&quot;python&quot;]">
    <a href="#" id="nav-button">
      <span>
        NAV
        <img src="images/navbar.png" alt="Navbar" />
      </span>
    </a>
    <div class="toc-wrapper">
        <div class="lang-selector">
              <a href="#" data-language-name="python">python</a>
        </div>
        <div class="search">
          <input type="text" class="search" id="input-search" placeholder="Search">
        </div>
        <ul class="search-results"></ul>
      <ul id="toc" class="toc-list-h1">
          <li>
            <a href="#welcome" class="toc-h1 toc-link" data-title="Welcome">Welcome</a>
          </li>
          <li>
            <a href="#installation" class="toc-h1 toc-link" data-title="Installation">Installation</a>
          </li>
          <li>
            <a href="#mission" class="toc-h1 toc-link" data-title="Mission">Mission</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#data-pipelines" class="toc-h2 toc-link" data-title="Data Pipelines">Data Pipelines</a>
                  </li>
                  <li>
                    <a href="#parallel-async-distributed" class="toc-h2 toc-link" data-title="Parallel/Async/Distributed">Parallel/Async/Distributed</a>
                  </li>
                  <li>
                    <a href="#for-data-science-and-data-engineering-with-love" class="toc-h2 toc-link" data-title="For data-science and data-engineering with love">For data-science and data-engineering with love</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#getting-started" class="toc-h1 toc-link" data-title="Getting started">Getting started</a>
          </li>
          <li>
            <a href="#stairs-project" class="toc-h1 toc-link" data-title="Stairs Project">Stairs Project</a>
          </li>
          <li>
            <a href="#stairs-app" class="toc-h1 toc-link" data-title="Stairs App">Stairs App</a>
          </li>
          <li>
            <a href="#app-components" class="toc-h1 toc-link" data-title="App components">App components</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#pipeline" class="toc-h2 toc-link" data-title="Pipeline">Pipeline</a>
                  </li>
                  <li>
                    <a href="#producer" class="toc-h2 toc-link" data-title="Producer">Producer</a>
                  </li>
                  <li>
                    <a href="#consumer" class="toc-h2 toc-link" data-title="Consumer">Consumer</a>
                  </li>
                  <li>
                    <a href="#flow" class="toc-h2 toc-link" data-title="Flow">Flow</a>
                  </li>
                  <li>
                    <a href="#app-config" class="toc-h2 toc-link" data-title="APP Config">APP Config</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#examples" class="toc-h1 toc-link" data-title="Examples">Examples</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#etl-example-hacker-news" class="toc-h2 toc-link" data-title="ETL example: hacker news">ETL example: hacker news</a>
                  </li>
                  <li>
                    <a href="#ml-example-bag-of-words" class="toc-h2 toc-link" data-title="ML example: bag of words">ML example: bag of words</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#features" class="toc-h1 toc-link" data-title="Features">Features</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#inspect-the-status-of-your-queues" class="toc-h2 toc-link" data-title="Inspect the status of your queues">Inspect the status of your queues</a>
                  </li>
                  <li>
                    <a href="#shell" class="toc-h2 toc-link" data-title="Shell">Shell</a>
                  </li>
                  <li>
                    <a href="#change-the-queue-streaming-server" class="toc-h2 toc-link" data-title="Change the queue/streaming server">Change the queue/streaming server</a>
                  </li>
                  <li>
                    <a href="#admin-panel" class="toc-h2 toc-link" data-title="Admin panel">Admin panel</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#faq" class="toc-h1 toc-link" data-title="FAQ">FAQ</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#what-is-the-reason-behind-apps" class="toc-h2 toc-link" data-title="What is the reason behind apps?">What is the reason behind apps?</a>
                  </li>
                  <li>
                    <a href="#why-does-the-pipeline-builder-use-quot-mocked-quot-data" class="toc-h2 toc-link" data-title="Why does the pipeline builder use "mocked" data ?">Why does the pipeline builder use "mocked" data ?</a>
                  </li>
                  <li>
                    <a href="#what-data-should-return-each-component-of-the-pipeline" class="toc-h2 toc-link" data-title="What data should return each component of the pipeline?">What data should return each component of the pipeline?</a>
                  </li>
                  <li>
                    <a href="#python-async" class="toc-h2 toc-link" data-title="Python async">Python async</a>
                  </li>
                  <li>
                    <a href="#quot-speed-and-power-quot-c-clarkson" class="toc-h2 toc-link" data-title=""Speed and Power" (c) Clarkson">"Speed and Power" (c) Clarkson</a>
                  </li>
              </ul>
          </li>
      </ul>
        <ul class="toc-footer">
            <li><a href='https://github.com/electronick1/stairs'>Stairs on github</a></li>
            <li><a href='https://github.com/electronick1/stairs_examples'>Stairs examples</a></li>
            <li><a href='https://github.com/electronick1/stairs_doc'>Stairs doc repo</a></li>
            <li><a href='https://github.com/electronick1/stepist'>Stepist on github</a></li>
        </ul>
    </div>
    <div class="page-wrapper">
      <div class="dark-box"></div>
      <div class="content">
        <h1 id='welcome'>Welcome</h1>
<p>version: 0.1.6</p>

<p>Stairs is a framework which allows you to slice and dice and make sense of 
your data. </p>

<p>It allows you to build data pipelines on top of streaming/queues services.
And make parallel, async, real-time or distributed calculations for most of your 
data  related tasks in a very simple and fast way.  </p>

<p>Stairs available for Python3, but you can write data processors in any language. 
You can also use any of streaming services which you want. </p>

<p>It&#39;s easy to start, test all your ideas or hypotheses in a quick way and it is 
ready for immediate use without any special magic. </p>

<p>It&#39;s faster and more scalable than &quot;Ray project&quot;, &quot;Luigi&quot; or &quot;Airflow&quot;.
<a href='#'>More about performance.</a></p>

<p>Start from Installation and then get an overview with <a href="/#getting-started">Get started</a>. </p>

<p><strong>Links:</strong> 
<br>
<a href='https://github.com/electronick1/stairs'>Stairs on github.</a>
<br>
<a href='https://github.com/electronick1/stairs_examples'>Stairs examples.</a>
<br>
<a href=''> Why Stairs? Stairs internals.</a>
<br>
<a href=''> Why we have data pipelines today? </a></p>
<h1 id='installation'>Installation</h1><pre class="highlight python tab-python"><code><span class="c"># install redis https://redis.io/topics/quickstart</span>
<span class="c"># sudo apt-get install redis</span>
<span class="c"># brew install redis</span>

<span class="n">pip</span> <span class="n">install</span> <span class="n">stairs</span><span class="o">-</span><span class="n">project</span>
</code></pre>
<blockquote>
<p>It&#39;s recommended to use the latest python 3 version.</p>
</blockquote>

<p>Just make <code>pip install stairs-project</code> to install stairs along with all 
python dependencies.</p>

<p>Stairs requires Redis for storing statistics and certain meta-information, 
even if you use a different streaming or queue service. </p>

<aside class="notice">
Stairs requires a running Redis server to work
</aside>
<h1 id='mission'>Mission</h1><h2 id='data-pipelines'>Data Pipelines</h2>
<!-- > ![image](images/data_pipeline.png) -->

<p>The main Stairs focus is data pipelines. It&#39;s a framework which helps you to
build and manipulate data through the chain of functions connected using
streaming or queues services. </p>

<p>You can think of it as of an MVP framework (like Django) for data pipelines.
Different layers of abstractions and components allow you to build any kind of 
data flow graphs and easily understand what&#39;s going on in your system. </p>

<p>Data pipelines is not only about ETL, you can also use Stairs for:<br> </p>

<ul>
<li>Training neural networks<br></li>
<li>Data analytics<br></li>
<li>Parsing and scrapping data<br></li>
<li>Real-Time Web applications<br></li>
</ul>

<p><a href="#">Why/How ETL able ot solve a wide range of tasks</a><br>
<a href='https://github.com/electronick1/stairs_examples'>Stairs examples.</a></p>
<h2 id='parallel-async-distributed'>Parallel/Async/Distributed</h2>
<!-- > ![parallel](images/parallel.png) -->

<p>Each data pipeline component can be represented as a separate python 
process (worker). Each component communicate with each other using 
streaming/queues services and together they can process your data in a parallel 
way.</p>

<p>Right now Stairs is using: <br>
- Redis queues <br>
- RMQ <br>
- SQS <br></p>

<p>You can easily connect new Streaming/Queue service as described 
<a href="#">here:</a></p>

<p>The Stairs framework focuses on speed and light, and the speed 
of your &quot;workers&quot; is limited mostly by your streaming/queues service. </p>

<p>Also internally Stairs has a strong inter-process communication service which
allows you to send hundreds of thousands messages per sec between two processes. </p>

<p><a href=''> Why Stairs? Stairs internals.</a></p>
<h2 id='for-data-science-and-data-engineering-with-love'>For data-science and data-engineering with love</h2>
<!-- > ![ds_en](images/ds_en.svg) -->

<p>Data-science and data-engineering are growing fast, and it&#39;s hard 
to be an expert in everything at the same time. </p>

<p>For example, to train ML models, you should spend about 80% of your time 
to process data -- your fast ability to process data and test 
all hypotheses will influence your final result.</p>

<p>Stairs allows a data-scientist to build &quot;scalable&quot; solutions without 
a high level of data-engineering skills.</p>

<ul>
<li>A data-scientist will focus only on data processing</li>
<li>A data-engineer will focus only on deploying part</li>
</ul>
<h1 id='getting-started'>Getting started</h1><pre class="highlight python tab-python"><code><span class="c"># script-like example as an alternative to default stairs project,</span>
<span class="c"># you can copy-paste it and simply execute. </span>
<span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">PipelineInfo</span><span class="p">,</span> <span class="n">DataPoint</span><span class="p">,</span> <span class="n">DataFrame</span>
<span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">StairsProject</span><span class="p">,</span> <span class="n">App</span>

<span class="c"># Init Stairs project</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">StairsProject</span><span class="p">()</span>
<span class="c"># Register Stairs App</span>
<span class="n">app</span> <span class="o">=</span> <span class="n">App</span><span class="p">(</span><span class="s">'core'</span><span class="p">)</span>
<span class="n">project</span><span class="o">.</span><span class="n">add_app</span><span class="p">(</span><span class="n">app</span><span class="p">)</span>


<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">main_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">:</span> <span class="n">PipelineInfo</span><span class="p">,</span> <span class="n">data_point</span><span class="p">:</span> <span class="n">DataPoint</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataFrame</span><span class="p">:</span>
    <span class="c"># pipeline which defines how functions will be connected and </span>
    <span class="c"># executed</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">data_point</span>
            <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">data_point</span><span class="p">)</span>
            <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">calculate_fibonacci</span><span class="p">)</span>
            <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">print_fib</span><span class="p">))</span>


<span class="nd">@app.producer</span><span class="p">(</span><span class="n">main_pipeline</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">generate_data</span><span class="p">():</span>
    <span class="c"># Producer which forward data to `main_pipeline`.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
        <span class="k">yield</span> <span class="nb">dict</span><span class="p">(</span><span class="n">data_point</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>


<span class="nd">@app.consumer</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">print_fib</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">result</span><span class="p">):</span>
    <span class="c"># consumer which working independently from pipeline</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Fibonacci for value </span><span class="si">%</span><span class="s">s, is: </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">result</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">calculate_fibonacci</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="c"># function which calculates fibonacci value</span>
    <span class="k">if</span> <span class="n">value</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">value</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">result</span><span class="o">=</span><span class="n">calculate_fibonacci</span><span class="p">(</span><span class="n">value</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)[</span><span class="s">'result'</span><span class="p">]</span> <span class="o">+</span>
               <span class="n">calculate_fibonacci</span><span class="p">(</span><span class="n">value</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)[</span><span class="s">'result'</span><span class="p">]</span>
    <span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="c"># compile pipeline, and connect all functions together. </span>
    <span class="n">main_pipeline</span><span class="o">.</span><span class="nb">compile</span><span class="p">()</span>
    <span class="c"># produce data to `main pipeline` using streaming service</span>
    <span class="n">generate_data</span><span class="p">()</span>
    <span class="c"># run pipelines, and consume data from streaming service</span>
    <span class="n">project</span><span class="o">.</span><span class="n">run_pipelines</span><span class="p">([</span><span class="n">main_pipeline</span><span class="p">],</span> <span class="n">die_when_empty</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre>
<p>In this section you will find how to run your first Stairs data 
pipeline and will get a very quick overview of Stairs components. This 
section covers Stairs functionality very superficially, and if you need 
full description of Stairs components skip this part. </p>

<p>When you are done with installation, let&#39;s try to kick-start your 
first Stairs project.</p>

<p>For this you need to type following command in shell:<br>
<code>
stairs-admin project:new name
</code></p>

<p>This command will generate default Stars project structure, where you will 
find following components:<br>
- <code>core</code> - package which represents &quot;core&quot; stairs app, with pipelines/consumer/producers components inside.<br>
- <code>config.py</code> - where all Stairs related configuration live.<br>
- <code>manage.py</code> - controller of Stairs project. It allows you to control 
stairs components using shell commands.<br></p>

<p>Inside <code>core</code> package you will find:<br>
- <code>app_config.py</code> - which defines Stairs App object.<br>
- <code>pipelines.py</code> - place where Stairs &quot;Pipelines&quot; functions lives. This 
functions are constructing data pipelines (as a chain/graph of functions).<br>
- <code>producers.py</code> - place where Stairs &quot;Producers&quot; functions lives. 
This functions will read data from data source, and forward everything to pipelines.<br>
- <code>consumers.py</code> - place where Stairs &quot;Consumers&quot; functions lives. This 
functions are able to save/export data to the global (e.g. database)<br>
- <code>flows.py</code> - place where you can find functions which were defined in 
pipelines. Exactly these functions are working with data. </p>

<blockquote>
<p>Note: all communication between stairs components happens using <code>Mapping</code> like
object (for example dict).</p>
</blockquote>

<p>In Stairs everything starts from producer. To move data from producer to 
pipeline you need to run producer function using shell command:<br>
<code>
python manage.py producer:run generate_data
</code>
<br>
This command will generate 20 items and forward them to streaming/queue service
(redis by default).</p>

<p>Then, you can run pipelines, simply call:<br>
<code>
python manage.py pipelines:run 
</code></p>

<p>This command will ask Stairs pipelines to consume data from streaming services 
and forward it to defined functions. In the end of pipeline it will be 
delivered to <code>consumer</code> and printed to console. </p>

<p>You can run multiple processes to start pipelines:<br>
<code>
python manage.py pipelines:run -p 10 
</code>
<br>
This command will run 10 independent processes which will handle data from 
producer. </p>

<p>Now you can scale and improve producer/pipeline/consumer functions in the 
way you want. If you want to use whole super power of Stairs, checkout next 
chapters where you will find full description of Stairs components. </p>

<p>Also checkout <a href='https://github.com/electronick1/stairs_examples'>Stairs examples.</a></p>
<h1 id='stairs-project'>Stairs Project</h1><pre class="highlight shell tab-shell"><code>stairs-admin project:new name
</code></pre>
<blockquote>
<p><img src="images/project.svg" alt="project" /></p>
</blockquote>

<p>StairsProject instance is the main control component in stairs. It&#39;s stores
configuration, apps, and db connections. It allows you to run app
components and get access to different parts of the system.</p>

<p>Stairs project consist of a set of Apps. Stairs apps were invited for
extensibility and flexibility, similar to Flask/Django philosophy.
Each stairs app has several components which represents data pipelines and
ETL concepts. </p>

<p>To create a default project template, just use the following command:</p>

<p><code>stairs-admin project:new name</code></p>

<p>This command will generate a basic project structure with one app inside, called
<code>core</code>. To control Apps and other components you can use <code>cli</code> service, which 
running by default in manage.py. It&#39;s similar to django, and it&#39;s allows you to
run producer or pipelines in one simple command. <br></p>

<p>By default StairsProject initialized in &quot;manage.py&quot; and reads settings from
&quot;config.py&quot;</p>

<p><code>manage.py</code> - it&#39;s a entry point to control everything inside stairs project.
It allows you to read a config, detect apps and execute different commands.<br>
<code>config.py</code> - allows you to define StairsProject settings and reassign
settings for your apps.</p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">StairsProject</span><span class="p">,</span> <span class="n">App</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">StairsProject</span><span class="p">(</span><span class="s">'config.py'</span><span class="p">)</span> <span class="c"># based on config file</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">StairsProject</span><span class="p">(</span><span class="n">redis_host</span><span class="o">=</span><span class="s">'localhost'</span><span class="p">,</span> <span class="n">redis_port</span><span class="o">=</span><span class="mi">6379</span><span class="p">)</span> 
<span class="n">project</span><span class="o">.</span><span class="n">add_app</span><span class="p">(</span><span class="n">App</span><span class="p">(</span><span class="s">'core'</span><span class="p">))</span>
<span class="n">project</span><span class="o">.</span><span class="n">get_app</span><span class="p">(</span><span class="s">'core'</span><span class="p">)</span>
</code></pre>
<p><br></p>

<p><code>manage.py</code> and <code>config.py</code> - it&#39;s a fast way to start your stairs project,
but you can always create your own StairsProject instance with all needed 
settings and apps. </p>

<p><br></p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">get_project</span>
<span class="n">my_project</span> <span class="o">=</span> <span class="n">get_project</span><span class="p">()</span>
</code></pre>
<p>You can always get the instance of the Stairs project from any place. And you
will have unlimited access to all apps and it&#39;s components. 
<br><br></p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">signals</span>

<span class="nd">@signals.on_project_ready</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">init_database</span><span class="p">():</span>
    <span class="k">pass</span>
</code></pre>
<p>Also as soon as Stairs project initialize and all components ready, it will
send a signal called <code>on_project_ready</code>. You can subscribe for it, as following:</p>

<p><br><br><br><br></p>
<h1 id='stairs-app'>Stairs App</h1><pre class="highlight shell tab-shell"><code>stairs-admin app:new name
</code></pre>
<blockquote>
<p><img src="images/app.svg" alt="app" /></p>
</blockquote>

<p>App collects all core components (pipelines, producers, consumers) in one
place and enviroment. </p>

<p>One of the reason why Apps have a place in Stairs - it&#39;s a flexible
customization and configuration. Stairs apps configuration allows you to
integrate and reuse external apps in different projects.</p>

<p>Each app has the following core components:</p>

<ul>
<li>a pipeline - represents a chain of functions which process your data. 
Each pipeline consists of multiple small components like custom functions or 
Stairs Flow components. <br></li>
<li>a producer - a function which helps you to read a source 
(a file, a database ...) and then forward data to pipeline through streaming 
service.<br></li>
<li>a consumer - a function which writes data to the data store or changes 
&quot;the global state&quot;.</li>
</ul>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">App</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">App</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"my_app"</span><span class="p">)</span>
</code></pre>
<p>To create a new &quot;default app&quot; template (with a packages and modules), 
type the following command:</p>

<p><code>stairs-admin app:new name</code></p>

<p>To define your app, you should initialize an App object with a name.
In &quot;default&quot; app template you can find this initialization in <code>app_config.py</code>.
But your are free to initialize Stairs App in any places you want.</p>
<pre class="highlight python tab-python"><code><span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">p</span><span class="p">):</span> <span class="k">pass</span>

<span class="nd">@app.producer</span><span class="p">(</span><span class="n">my_pipeline</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">my_producer</span><span class="p">():</span>
    <span class="k">yield</span> <span class="nb">dict</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="s">"hello world"</span><span class="p">)</span>
</code></pre>
<p>If you want to add a new app to the project, populate 
<code>apps</code> variable in the config file or use <code>get_project().add_app(app)</code></p>

<p>You can add new components to your app simply wrapping your function by
app.component decorator, for example:</p>

<p>As soon as app component initialized with a function or method, it will be
registered inside App and store at App.components field.</p>
<pre class="highlight python tab-python"><code><span class="n">app</span> <span class="o">=</span> <span class="n">App</span><span class="p">()</span>
<span class="n">app_producers</span> <span class="o">=</span> <span class="n">app</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">producers</span>
<span class="n">app_pipelines</span> <span class="o">=</span> <span class="n">app</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">pipelines</span>
<span class="n">my_pipeline</span> <span class="o">=</span> <span class="n">app</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"my_pipeline"</span><span class="p">)</span>
<span class="n">my_pipeline</span> <span class="o">=</span> <span class="n">app</span><span class="o">.</span><span class="n">get_pipeline</span><span class="p">(</span><span class="s">"my_pipeline"</span><span class="p">)</span> <span class="c"># shortcuts</span>
</code></pre>
<p><br><br>
You can access all stairs components using app instance. It specially useful 
when you want to control components manually. For example you can add data 
to pipeline <code>my_pipeline.add_job(dict(a=1))</code> or run pipeline 
<code>get_project().run_pipelines(my_pipeline)</code>.
It&#39;s very easy to do using shell <code>python manage.py shell</code></p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code><span class="n">app</span> <span class="o">=</span> <span class="n">App</span><span class="p">(</span><span class="s">'core'</span><span class="p">)</span>
<span class="n">app</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">'/'</span><span class="p">)</span>
<span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">'/main'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
</code></pre>
<p>App configuration is a simple dict like object. You can safely redefine or
update it in any places. App settings useful to control pipelines building 
process or when you plan to include App to a different project and apply
some customization there.     </p>

<p><br><br><br><br>
Stairs App sends a signals when it&#39;s ready or initialized. Example:</p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs.signals</span> <span class="kn">import</span> <span class="n">on_app_ready</span>

<span class="nd">@on_app_ready</span><span class="p">(</span><span class="s">"app_name"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">init_smth</span><span class="p">(</span><span class="n">app</span><span class="p">):</span>
    <span class="k">pass</span>
</code></pre>
<p>Signals:<br>
- on_app_created - when app instances created <br>
- on_app_ready - when all app compoenents compiled and ready to use <br></p>

<p><br><br><br>
Basic app schema: </p>

<p><img src="images/app_2.svg" alt="image" /></p>
<h1 id='app-components'>App components</h1><h2 id='pipeline'>Pipeline</h2><pre class="highlight python tab-python"><code>
<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">my_function_which_process_data</span><span class="p">,</span> <span class="n">as_worker</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> \
                <span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">MySecondFlow</span><span class="p">())</span>\
                <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_result</span><span class="p">)</span>

</code></pre>
<p>The pipeline is a way to combine multiple objects (functions/classes/other 
pipelines) in one big graph. It&#39;s all about building a graph of handlers 
for process your data.</p>

<p>The way it works is a bit tricky, but it&#39;s quite simple to understand and use. 
The input of each pipeline can be any data you want, then you can subscribe 
more and more handlers to these data and create a graph which will describe how
your data must be processed.</p>

<p>Each component of the pipeline can be a worker, which communicates with other 
components through a streaming/queue service. And it will be possible to run
this components in separate processes.</p>
<pre class="highlight python tab-python"><code><span class="n">python</span> <span class="n">manage</span><span class="o">.</span><span class="n">py</span> <span class="n">pipelines</span><span class="p">:</span><span class="n">run</span>
<span class="n">python</span> <span class="n">manage</span><span class="o">.</span><span class="n">py</span> <span class="n">pipelines</span><span class="p">:</span><span class="n">run</span> <span class="o">-</span><span class="n">p</span> <span class="mi">10</span> <span class="c"># start 10 processes </span>
<span class="n">python</span> <span class="n">manage</span><span class="o">.</span><span class="n">py</span> <span class="n">pipelines</span><span class="p">:</span><span class="n">run</span> <span class="n">app_name</span><span class="o">.</span><span class="n">pipeline_name</span>
<span class="c"># or</span>
<span class="n">get_project</span><span class="p">()</span><span class="o">.</span><span class="n">run_pipelines</span><span class="p">(</span><span class="n">my_pipeline</span><span class="p">)</span>
</code></pre>
<p>To run a pipeline (and let data go through the components of the pipeline) you
can use <code>manage.py</code> command or run it directly from the project. 
Process will start consuming data from streaming service and forward data 
through  defined chain of functions.  </p>

<p><br><br>
When you are running pipeline, it expects that data already in streaming service.
Therefore you should forward some data to pipeline (streaming service) here at 
least four options to do that:</p>

<ul>
<li>Run the Stairs producers (producer component section for more details)</li>
<li>Execute one pipeline from another <code>data.call_pipeline(my_pipeline)</code></li>
<li>Add data to pipeline manually <code>my_pipeline.add_job(data)</code></li>
<li>Add data to pipeline from none-python env/lang, using queue/streaming
service, just pull some jobs to <code>pipeline.get_queue_name()</code> queue</li>
</ul>

<p><br>
Next section will describe internals of Stairs pipeline. And you will see, how
to build a complex graphs of functions, which are easy to undestand and use.   </p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">concatenate</span>
<span class="kn">from</span> <span class="nn">.app_config</span> <span class="kn">import</span> <span class="n">app</span>

<span class="nd">@app.pipeline</span>
<span class="k">def</span> <span class="nf">short_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value1</span><span class="p">,</span> <span class="n">value2</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">concatenate</span><span class="p">(</span><span class="n">data_point1</span><span class="o">=</span><span class="n">value1</span><span class="p">,</span> <span class="n">data_point2</span><span class="o">=</span><span class="n">value2</span><span class="p">)</span>
            <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">my_function</span><span class="p">)</span>
            <span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"result_data_point"</span><span class="p">)</span>
            <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">my_function_2</span><span class="p">())</span>
            <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="s">'result_data_point'</span><span class="p">))</span>


<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">detailed_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value1</span><span class="p">,</span> <span class="n">value2</span><span class="p">):</span>
    <span class="c"># combing all values tougher</span>
    <span class="n">data_frame</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">(</span><span class="n">data_point1</span><span class="o">=</span><span class="n">value1</span><span class="p">,</span> <span class="n">data_point2</span><span class="o">=</span><span class="n">value2</span><span class="p">)</span>

    <span class="c">#subscribe a function which will change data frame values</span>
    <span class="c">#and return new set of data (DataFrame)</span>
    <span class="n">my_flow_result</span> <span class="o">=</span> <span class="n">data_frame</span><span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">my_function</span><span class="p">)</span>

    <span class="c"># Extract particular value (DataPoint)</span>
    <span class="n">flow_data_point</span> <span class="o">=</span> <span class="n">my_flow_result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"result_data_point"</span><span class="p">)</span>

    <span class="c"># Subscribe a function and rename all at once</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">flow_data_point</span>\
      <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">my_function_2</span><span class="p">)</span>\
      <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="s">'result_data_point'</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span>


</code></pre><h3 id='manipulating-data-inside-the-pipeline'>Manipulating data inside the pipeline</h3>
<p>The input of the stairs pipeline is <a href="https://en.wikipedia.org/wiki/Mock_object">&quot;mock&quot;</a>
values called &quot;DataPoint&#39;s&quot;. It&#39;s a representation of a future data which will be 
consumed (came) from streaming/queue service and forwarded inside pipeline
(to functions which you defined). </p>

<p>&quot;Real&quot; data will be accessible only inside the functions and flows, 
which you &quot;subscribed&quot; to the &quot;DataPoint&#39;s&quot;. (you can NOT use &quot;real&quot; values 
directly inside the pipeline builder (<code>@app.pipeline()</code>) 
- this function is just for building functions graph, not for data manipulations.</p>

<p>You can subscribe the DataPoint with some functions or a Flow components
and the result of this subscription will be a new object called &quot;DataFrame&quot; 
(a kind of the dict representation of DataPoints {key:DataPoint} structure) - 
it represents the result of your data handler (function/flow) after execution.</p>

<p>Each component of data pipeline (subscribed functions) should always return
&quot;Mapping&quot; like object (e.g. python dict). The Mapping object is called &quot;DataFrame&quot;
inside stairs pipeline and you can subscribe any function to it. One value of this 
dict called &quot;DataPoint&quot;. 
You can always extract DataPoints from DataFrames using <code>get(&#39;value&#39;)</code>.</p>

<p>Now the most interesting part: if you want to combine multiple 
DataPoints or DataFrames into one object, you can use 
the <br> <code>concatenate(value1=data_point, value2=data_point2)</code> 
function, which returns the DataFrame with defined arguments.</p>

<p>If you want to modify your DataFrame, you can use the <code>rename(value=new_value)</code> 
method, and the result will be a new DataFrame. </p>

<p>As you can see, it&#39;s quite simple to define such complex 
architecture just with 6 code lines. And it&#39;s a bit similar 
to how we define Neural Networks using <a href="https://keras.io/">Keras</a>.</p>

<p><br></p>

<p><img src="images/pipeline_2.svg" alt="image" /></p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">MyFlow</span><span class="p">(),</span> <span class="n">as_worker</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> \
                <span class="o">.</span><span class="n">apply_flow</span><span class="p">(</span><span class="n">MySecondFlow</span><span class="p">())</span>\
                <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_result</span><span class="p">)</span>

</code></pre><h3 id='how-each-pipeline-component-changes-data'>How each pipeline component changes data.</h3>
<p>The components (e.g. functions) of the pipeline are able to accumulate data or 
completely redefine it. As was mentioned before, result of each function should
be &quot;Mapping&quot; like object (e.g. python dict) and during pipeline executing we
basically manipulating by this &quot;dicts&quot; objects.</p>

<p>During pipeline execution result of the one function could be input for another. 
This dict like object changes after each function - we can update data, 
or completely redefine by result of the last function.</p>

<p>For this stairs has three definitions: <br>
- subscribe_<br>
- apply_ <br>
- call_<br></p>

<ul>
<li>to subscribe - to accumulate/update current data by result of the stairs 
component (e.g. function) <br> </li>
<li>to apply - to completely redefine data based on the pipeline component result.<br></li>
<li>to call - used to execute pipelines as a standalone components which not 
influence to current data.<br> </li>
</ul>

<p><br><br></p>

<p><img src="images/pipeline_3.svg" alt="image" /></p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code>
<span class="k">def</span> <span class="nf">custom_function</span><span class="p">(</span><span class="n">new_value</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">new_value</span><span class="o">=</span><span class="n">new_value</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>


<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">base_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span>\
        <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="k">lambda</span> <span class="n">value</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">new_value</span><span class="o">=</span><span class="n">value</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">'plus_one'</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">custom_function</span><span class="p">,</span> <span class="n">as_worker</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre><h3 id='types-of-components-which-changes-data'>Types of components which changes data.</h3>
<p>You can subscribe any functions to your data. But Stairs has a lot more cool
components, which allows you to process data in a very efficient way. </p>

<ul>
<li>functions - you can subscribe/apply regular functions to your Data, inside
pipeline<br>.</li>
<li>lambda functions - you can subscribe/apply lamda functions (it&#39;s quite 
important to set a name for &#39;lamda&#39; function).</li>
<li>function as a producer - you subscribe/apply functions which could yield data
and be as a generators of the data inside pipeline.</li>
<li>flow - it&#39;s a special Stairs object, which combine set of simple functions
into one very high level representation (see more in next chapters).</li>
<li>another pipeline - you can subscribe/apply another pipelines to current data.<br></li>
</ul>

<p>Note: all these components must return the <code>dict</code> object. And all communication
between stairs components happens using Mapping like objects.</p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">base_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">BaseFlow</span><span class="p">(</span><span class="o">**</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span><span class="p">))</span>

<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_pipeline</span><span class="p">(</span><span class="n">base_pipeline</span><span class="p">)</span>\
                <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_result</span><span class="p">)</span>

<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline_with_config</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">use_lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_pipeline</span><span class="p">(</span><span class="n">base_pipeline</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>\
                <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_result</span><span class="p">)</span>

</code></pre><h3 id='chain-pipelines'>Chain pipelines.</h3>
<p>Each pipeline is a &quot;worker&quot; which consume data from streaming/queues services
and forward it to defined functions inside. </p>

<p>You can chain multiple pipelines into one using three different options:</p>

<p>-<code>.subscribe_pipeline(pipeline2)</code> - it will copy all steps from &quot;pipeline2&quot;
to current pipeline and execute first step of this pipeline as a &quot;worker&quot;, 
result of this pipeline will update &quot;current data&quot;. (!)It&#39;s not very performance 
friendly operation.<br>
-<code>.apply_pipeline(pipeline2)</code> - like a &#39;subscribe_pipeline&#39; it will copy all 
steps from &quot;pipeline2&quot; to current one, but will completely redefine 
&quot;current data&quot; by result of new pipeline. It works much faster then 
&#39;subscribe_pipeline&#39;<br>
-<code>.call_pipeline(pipeline2)</code> - it will forward all data to &quot;pipeline2&quot; and 
execute it completely isolated from current pipeline. Result of this method
don&#39;t update current data. It&#39;s a very fast operation, but not change data
in current pipeline. </p>
<pre class="highlight python tab-python"><code><span class="nd">@app.pipeline</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">cleanup_function</span><span class="o">=</span><span class="n">base_cleanup_function</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">base_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cleanup_function</span><span class="p">)</span>

<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_pipeline</span><span class="p">(</span>
        <span class="n">base_pipeline</span><span class="p">,</span> 
        <span class="n">config</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">cleanup_function</span><span class="o">=</span><span class="n">lamda</span> <span class="n">value</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
</code></pre>
<p><br>
One of the core stairs pipelines feature is a scalable way to configure them. 
The structure of the app and pipelines is quite friendly to configuration, 
you can set new config values and then call a new pipeline.</p>

<p><code>value.subscribe_pipeline(base_pipeline, config=dict(path=&#39;/home&#39;))</code></p>

<p>These values will be available inside <code>base_pipeline</code> as:</p>

<p><code>base_pipeline.config.get(&#39;path&#39;)</code></p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code>
<span class="k">def</span> <span class="nf">custom_function</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">new_value</span><span class="o">=</span><span class="n">new_value</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>


<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">base_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span>\
        <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">custom_function</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s">'/tmp/save_data.txt'</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_to_file</span><span class="p">,</span> <span class="n">as_worker</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre><h3 id='custom-constant-values'>Custom/constant values</h3>
<p>It&#39;s possible to add extra values (with real data) into your pipeline components. </p>

<p>It is useful if you want to configure something with constant variables or use the
pipeline config:</p>

<p><code>data.add_value(url=pipeline.config.get(&#39;url&#39;))</code></p>

<p><br><br><br><br><br></p>
<h2 id='producer'>Producer</h2>
<p>Producer is a set of components for reading data from any source you want,
and then forward this data to pipelines (through streaming services). </p>

<p>So far, we have four types of the producer components: <br></p>

<ul>
<li>a simple producer <br></li>
<li>a batch producer - a way to read your data in batches safely <br></li>
<li>a redirect producer - wrapp around simple_producer which allows to call 
another pipelines<br></li>
<li>a spark producer - a way to execute spark RDD graph and pass data to 
pipelines<br></li>
</ul>

<p><br><br></p>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.producer</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">my_pipeline</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_file</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">FILE_PATH</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">yield</span> <span class="nb">dict</span><span class="p">(</span><span class="n">row</span><span class="o">=</span><span class="n">row</span><span class="p">)</span>
</code></pre><h3 id='simple-producer'>Simple Producer</h3>
<p>It&#39;s an iterator function which yields data to defined pipelines. 
You can run this &quot;producer&quot; from the console:<br>
<code>python manage.py producer:run producer_name</code><br>
or, simply call it: <code>my_producer()</code></p>

<p>Then Stairs will iterate by data which were yield from producer and 
forward everything to pipeline (through streaming service)</p>

<p>Producer should always yield Mapping like object (e.g. dict). </p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">producer_signals</span>
<span class="nd">@app.producer</span><span class="p">(</span><span class="n">my_pipeline</span><span class="p">,</span>
          <span class="n">repeat_on_signal</span><span class="o">=</span><span class="n">producer_signals</span><span class="o">.</span><span class="n">on_pipeline_empty</span><span class="p">,</span>
          <span class="n">repeat_times</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">my_producer</span><span class="p">():</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">()</span>
</code></pre>
<p>It&#39;s also possible to auto-repeat producer based on different signals. 
You can specify producer signal (or write your own), and amount of times 
you would like to repeat producer. As soon as signal function will return &quot;True&quot;,
producer will start executing again. Its useful, for example, for training 
neural networks, when you need to send data multiple times.   </p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.producer</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">read_batch</span><span class="p">(</span><span class="n">batch_id</span><span class="p">):</span>
    <span class="n">interval</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_id</span><span class="o">*</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_id</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s">"SELECT * FROM table where id&gt;</span><span class="si">%</span><span class="s">s and id&lt;</span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="n">interval</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">cursor</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">row</span>


<span class="nd">@app.batch_producer</span><span class="p">(</span><span class="n">read_batch</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_database</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">AMOUNT_OF_ROWS</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">):</span>
        <span class="k">yield</span> <span class="nb">dict</span><span class="p">(</span><span class="n">batch_id</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>

</code></pre><h3 id='batch-producer'>Batch Producer</h3>
<p>It&#39;s a parallel/distributed way to read data in batches. This is a next level
of simple producer.</p>

<p>Batch producer return/yields data (jobs) (which will be input for Producer), 
and then this data goes to the streaming service. In a separate process
simple producer starts consuming those data and forward to pipeline. </p>

<p>The idea is to split your data into batches and read each batch independently. 
If the whole batch had read successfully, it goes to the pipeline (in case of redis
queue with one transaction, in case of others - one by one). </p>

<p>To start batch producer, which will generate jobs for simple producer,
simply run:<br>
<code>python manage.py producer:run batch_producer_name</code></p>

<p>It will start pulling data to &quot;simple producer&quot;. Then you should tell &quot;simple
producer&quot; to start consuming jobs from streaming queue:<br>
<code>python manage.py producer:run_jobs simple_producer_name</code></p>

<p>You can run multiple of this ^ processes and make batch reading more fast and
parallel.</p>

<p>Similar to Simple Producer, you can specify &quot;repeating&quot; signals. </p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code><span class="nd">@app.producer</span><span class="p">(</span><span class="n">my_pipeline</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">my_producer</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="k">yield</span> <span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nd">@app.producer_redirect</span><span class="p">(</span><span class="n">based_on</span><span class="o">=</span><span class="n">my_producer</span><span class="p">,</span> <span class="n">my_new_pipeline</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">my_producer_2</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">data</span>

</code></pre><h3 id='redirect-producer'>Redirect Producer</h3>
<p>The way to execute some producer with a different set of pipelines.</p>

<p>It will simply run <code>based_on</code> producer, and forward result to current
function. Then it will forward result of this function to newly 
defined pipelines.</p>

<p>Its a good way to customize input data for different pipelines, without 
rewriting or duplicating producers.</p>

<p><br><br><br></p>
<h3 id='spark-producer'>Spark Producer</h3><pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="n">appName</span><span class="o">=</span><span class="s">"app"</span><span class="p">)</span>

<span class="nd">@app.spark_producer</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_json_files</span><span class="p">():</span>
  <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span> \
      <span class="o">.</span><span class="n">builder</span>\
      <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

  <span class="n">f</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"test.row_json"</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
  <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">df</span>
</code></pre>
<p>The Spark producer is a way to read your data using spark power and then pull 
everything to the Stairs pipelines. </p>

<p>Spark has powerful features to read data in fast parallel way and it could be helpful
when you want to read big amount of data, filter it and process using Stairs pipelines.</p>

<p>In the background Stairs iterates over each partition, create connection to your
queue/streaming service and add job one by one to a queue. Checkout internal 
implementation <a href="#">here</a></p>

<p>To run spark producer you should run following command:<br>
<code>python manage.py producer:run spark_producer_name</code></p>

<p>It will start executing Spark context and pull data to pipelines. </p>
<h2 id='consumer'>Consumer</h2><pre class="highlight python tab-python"><code><span class="nd">@app.consumer</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">save_to_redis</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">):</span>
    <span class="n">redis</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>


<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">aggregate_smth</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_to_redis</span><span class="p">)</span>
</code></pre>
<p>The consumer is a set of components for writing/saving your data to any type 
of store or for changing the global state of your system.</p>

<p>You are free to write/save your data inside the inside pipeline functions, 
but the consumer is not only about saving. It is also a way to accumulate all
data to one place and achive true fault tolerance.</p>

<p>Stairs has 3 types of consumers:<br>
- <code>@app.consumer()</code> is a simple function which should not return any data. 
It&#39;s useful for saving data to the data store.<br>
- <code>@app.standalone_consumer()</code> is a function which can be called as a separate process. 
It&#39;s useful for writing data to a file or for accumulating them inside one process.<br> 
- <code>@app.consumer_iter()</code> is a function which yields data from the pipeline.
It&#39;s useful when you want to train e.g. a neural network. It is plays role of 
data generator/iterator.<br></p>
<pre class="highlight python tab-python"><code><span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span>
            <span class="n">my_consumer</span><span class="p">,</span> 
            <span class="n">when</span><span class="o">=</span><span class="k">lambda</span> <span class="n">value</span><span class="p">:</span> <span class="n">value</span> <span class="o">==</span> <span class="s">"hello"</span>
    <span class="p">)</span>
</code></pre>
<p>Cool feature:<br>
You can specify &quot;when&quot; attribute for subscribe consumer inside pipeline, and 
this consumer will be executed only if &quot;when function&quot; return True</p>

<p><br></p>

<p>Consumer do NOT apply any changes to the data, when you subscribe it to your data
it will execute in the background without any influence to your pipeline data.
It&#39;s also possible (and recommended) to run consumers as a &quot;workers&quot;. </p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code><span class="kn">import</span> <span class="nn">json</span>

<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">"file.txt"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span>

<span class="nd">@app.standalone_consumer</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">write_to_file</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">):</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">save_data</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">write_to_file</span><span class="p">)</span>
</code></pre><h3 id='standalone-consumer'>Standalone Consumer</h3>
<p>Standalone consumer is the same component as a &quot;app.consumer&quot;, but
it will be executed only in a separate process.</p>

<p>Function in pipeline (one process) -&gt; Streaming service -&gt; Standalone consumer(another process)</p>

<p>Standalone consumer is always &quot;worker&quot;, and to start executing jobs you
need to run cli command:<br>
<code>python manage.py consumer:standalone app.write_to_file</code><br>
or <code>write_to_file.run_worker()</code></p>

<p>It is useful if you need to write or perform data inside one process only.</p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.consumer_iter</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">train_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>


<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">prepare_data_for_nn</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>    
    <span class="k">return</span> <span class="p">(</span><span class="n">data</span>
            <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">prepare_for_nn</span><span class="p">)</span>
            <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">train_data</span><span class="p">))</span>


<span class="c"># in a separate process</span>
<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">train_data</span><span class="o">.</span><span class="nb">iter</span><span class="p">())</span>
</code></pre><h3 id='consumer-iter'>Consumer Iter</h3>
<p>It&#39;s a standalone consumer (similar to <code>app.standalone_consumer</code>) but,
it will yield all data back to the process which called consumer.iter() method.</p>

<p>The <code>@app.consumer_iter()</code> component allows you to read data directly from the 
streaming/queue service. You can iterate data which was passed to consumer from
any place you want. Simply call <code>my_consumer_iter.iter()</code></p>

<p><br><br><br></p>
<h2 id='flow'>Flow</h2><pre class="highlight python tab-python"><code><span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">first_step_result</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">first_step</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">first_step_result</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">second_step_result</span><span class="o">=</span><span class="n">first_step_result</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MyFlow2</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">third_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">first_step_result</span><span class="p">,</span> <span class="n">second_step_result</span><span class="p">):</span>
        <span class="c"># which actually means value * 3</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">flow_result</span><span class="o">=</span><span class="n">value</span><span class="o">+</span><span class="n">first_step_result</span><span class="o">+</span><span class="n">second_step_result</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">third_step</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">first_step_result</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">second_step_result</span><span class="o">=</span><span class="n">first_step_result</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">first_step_result</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>  
</code></pre>
<p>The Flow is a high-level component which actually defines the data pipeline. 
And it&#39;s a &quot;next level&quot; over pipelines functions. </p>

<p>You can call &quot;Flow&quot; almost like a function, but inside, it will be able to 
execute complex graphs of functions. <code>data_frame.subscribe_flow(MyFlow)</code></p>

<p>The problem with data pipelines builders is that it&#39;s not quite easy to 
change/redefine something, also, a great amount of functions
makes pipelines like a hell of dependencies (luigi is a good example of it). <br></p>

<p>To solve these problems, we have the FLOW component which can be used to: <br>
- change/redefine/extend your pipeline easily (just use python inheritance)<br>
- configure easily<br>
- easily understand what&#39;s going on<br>
- each Flow can be a worker - the Flow has steps which should be run inside
 another worker<br></p>

<p>The Flow represents a data flow graph (in a class) as a chain of functions 
called &quot;steps&quot;. You can connect these steps simply by defining the 
&quot;next step&quot; in the decorator:</p>

<p><code>@step(next_step, next_step ... )</code></p>

<p>The input for the next step is the output from the current. The result of each
step is accumulating, which means that from any low-level steps you will be 
able to get values from high-level steps. <br>
The last step in your graph should be defined with the next step set to None.</p>

<p><code>@step(None)</code></p>

<p>All steps are executed in one &quot;worker&quot; (process).<br>
The structure of the <code>Flow</code> class was actually inspired by <a href="https://github.com/electoronick1/stepist">stepist</a></p>

<p>Next you will find, many cool features of &quot;Flow&quot; components, which will improve
you experience with Stairs and data processing.  </p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">FLow</span><span class="p">,</span> <span class="n">step</span>

<span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result_for_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_stats</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">result_for_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">calculate_stats</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">result_for_2</span><span class="o">.</span><span class="n">validate_data</span><span class="o">.</span><span class="n">value</span> <span class="o">+</span>
                <span class="n">result_for_4</span><span class="o">.</span><span class="n">validate_data</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">validate_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">validate_data</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">calculate_stats</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

</code></pre><h3 id='how-to-run-execute-flow-component'>How to run/execute Flow component.</h3>
<p>When you defined chain of steps, you will need to tell Stairs how to run this
chain, and what data to return back to the pipeline. For this you need to define
<code>__call__</code> method.</p>

<p>Inside the <code>__call__</code>, you can execute any step from your flow. 
Then the whole chain of steps will be executed, until step with (next_step=None) </p>

<p><code>self.mystep(**kwargs_for_highest_step)</code><br>
or<br>
<code>self.start_from(self.mystep, **kwargs_for_highest_step)</code></p>

<p>During chain execution each step could potentially save intermediate results. 
steps where next_step is None - always save data inside. All this intermediate
data will be store in the object which will be returned back to <code>__call__</code>,
after (for example) <code>.start_from</code> method. You can access it as following:<br>
<code>data = self.start_from(self.mystep, **kwargs_for_highest_step)</code><br>
<code>last_step_data = data.last_step</code></p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">FLow</span><span class="p">,</span> <span class="n">step</span>

<span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_from</span><span class="p">(</span><span class="n">first_step</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">first_step</span><span class="p">,</span> <span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">second_step</span><span class="p">}</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power3</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step</span><span class="p">,</span> <span class="n">save_result</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power2</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</code></pre><h3 id='get-intermediate-result'>Get intermediate result.</h3>
<p>It&#39;s also possible to customize steps, which should return the data result back. 
Just set the <code>save_result</code> flag to True. </p>

<p><br></p>

<p><img src="images/flow2.svg" alt="image" /></p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">FLow</span><span class="p">,</span> <span class="n">step</span>

<span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_from</span><span class="p">(</span><span class="n">first_step</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">first_step</span><span class="p">,</span> <span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">second_step</span><span class="p">}</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power3</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step</span><span class="p">,</span> <span class="n">save_result</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power2</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MyFlow2</span><span class="p">(</span><span class="n">MyFlow</span><span class="p">):</span>
    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step</span><span class="p">,</span> <span class="n">save_result</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power4</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">4</span><span class="p">)</span>

<span class="c"># ------ pipelines</span>

<span class="n">default_flow</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">my_flow</span><span class="o">=</span><span class="n">MyFlow</span><span class="p">)</span>
<span class="n">new_cool_flow</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">my_flow</span><span class="o">=</span><span class="n">MyFlow2</span><span class="p">)</span>

<span class="nd">@app.pipeline</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">default_flow</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">base_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"my_flow"</span><span class="p">))</span>

<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">new_cool_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_pipeline</span><span class="p">(</span><span class="n">base_pipeline</span><span class="p">,</span> 
                                  <span class="n">config</span><span class="o">=</span><span class="n">new_cool_flow</span><span class="p">)</span>
</code></pre><h3 id='expand-and-scale-flow-component'>Expand and Scale Flow component.</h3>
<p>The one of the main benefit of the Stairs flow it&#39;s a scalable way to easily
change your data manipulation chain without losing consistency. No matter how 
much hypotheses you have, you will always have a good picture of your data flow
graph. <br>
In case of data science tasks it&#39;s useful when you want to test a
lot of hypotheses and you have a lot of different ways to solve a problem. </p>

<p>The flow is a class, which means that we can use inheritance 
to redefine the logic of certain steps. Then you can use newly created Flow
in pipeline. </p>

<p><br><br><br></p>

<p><img src="images/flow3.svg" alt="image" /></p>

<p><br><br><br><br><br><br></p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">FLow</span><span class="p">,</span> <span class="n">step</span>

<span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_from</span><span class="p">(</span><span class="n">first_step</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">first_step</span><span class="p">,</span> <span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">second_step</span><span class="p">}</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power3</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step</span><span class="p">,</span> <span class="n">save_result</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power2</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MyFlow2</span><span class="p">(</span><span class="n">MyFlow</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__reconnect__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">second_step</span><span class="o">.</span><span class="n">set_next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">third_step</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">second_step</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="n">save_result</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">third_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power4</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">4</span><span class="p">)</span>
</code></pre><h3 id='reconnect-steps-inside-flow'>Reconnect steps inside Flow.</h3>
<p>The inheritance also allows you to reconnect certain steps and change the 
Flow structure.</p>

<p>It&#39;s possible to add a new step to the top, 
insert it in the middle or add the &quot;save_result&quot; flag.</p>

<p><br></p>

<p><img src="images/flow4.svg" alt="image" /></p>

<p><br><br><br></p>
<pre class="highlight python tab-python"><code><span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step_2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step_1</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step_1</span><span class="p">,</span> <span class="n">second_step_2</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c"># this step will be executed right after</span>
        <span class="c"># root1 and root2</span>
        <span class="c"># data from root1 and root2 will be merge into current step</span>
        <span class="k">pass</span>
</code></pre><h3 id='complex-graph-with-multiple-branches'>Complex graph with multiple branches</h3>
<p>You can define multiple &quot;next&quot; steps, and this will allow you to build complex 
branchy pipelines, like in the example below:
<br><br></p>

<p><img src="images/flow1.svg" alt="image" /></p>

<p><br><br><br></p>
<h2 id='app-config'>APP Config</h2><pre class="highlight python tab-python"><code>
<span class="c"># app_config.py</span>

<span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">App</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">App</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"myapp"</span><span class="p">)</span>
<span class="n">app</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s">"use_validation"</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>

<span class="c"># pipelines.py</span>

<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">my_function</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_validation</span><span class="p">:</span>
        <span class="n">result</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">ValidationFLow</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">result</span>

<span class="c"># another project</span>

<span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_validation</span> <span class="o">=</span> <span class="bp">True</span>
</code></pre>
<p>It&#39;s a place where you can setup your app. </p>

<p>You can define any settings you want for your app, and then when you introduce
your app to the new project, those settings could be easily overwritten. This 
customization allows you to support project extensibility on a very high level,
like it implemented in Flask or Django frameworks.</p>

<p><br></p>
<h1 id='examples'>Examples</h1><h2 id='etl-example-hacker-news'>ETL example: hacker news</h2>
<p><a href="https://github.com/electronick1/stairs_examples/tree/master/hacker_news">github hacker_news</a><br></p>

<p>The idea here is to extract data from a certain source (in this case it&#39;s 
google cloud), to change them somehow and save them in a elegant format 
(for example, for creating charts later or for building neural networks).</p>

<p>You can start exploring this project from <code>producers.py</code> 
inside the hacker_new app. <br></p>

<p>Each producer will send data to the pipelines, in our case we have two of them:<br>
- <code>cleanup_and_save_localy</code> - makes a basic text cleanup and filtering
- <code>calculate_stats</code> -  based on &quot;clean&quot; data, it calculates stats we need</p>

<p>The next (and the last) <code>consumers.py</code> - a place where all data come at the end 
of the pipeline and aggregated in redis. </p>

<p><br></p>
<h2 id='ml-example-bag-of-words'>ML example: bag of words</h2>
<p><a href="https://github.com/electronick1/stairs_examples/tree/master/bag_of_words">github bag of words</a><br></p>

<p>Here, we try teaching the neural network to solve 
<a href="https://www.kaggle.com/c/word2vec-nlp-tutorial">kaggle task &quot;Bag of Words Meets Bags of Popcorn&quot;</a></p>

<p>This example is based on <a href="https://github.com/wendykan/DeepLearningMovies/">this repo</a>,
and it&#39;s a kind of the copy-paste solution, but for much better representation.</p>

<p>What does &quot;better representation&quot; mean? </p>

<p>If you look inside this repo, it&#39;s just a plain code. 
If you want to make calculations in a parallel way, it&#39;s not very trivial task to do.
Also, if you want to change something, it&#39;s not easy to undestand
all the changes of the data flow.</p>

<p>Stairs solves all these problems:</p>

<ul>
<li>It makes calculations in the parallel by default</li>
<li>You can easily understand what&#39;s going on inside the <code>pipelines.py</code></li>
<li>It is super easy to change something (just redefine certain methods in the FLow classes).</li>
</ul>
<h1 id='features'>Features</h1><h2 id='inspect-the-status-of-your-queues'>Inspect the status of your queues</h2><pre class="highlight shell"><code>python manage.py inspect:status app_name

<span class="c"># Queue: cleanup_and_save_localy</span>
<span class="c"># Amount of jobs: 10000</span>
<span class="c"># Queue decreasing by 101.0 tasks per/sec</span>


python manage.py inspect:monitor app_name

<span class="c"># Queue: cleanup_and_save_localy</span>
<span class="c"># Amount of jobs: 3812</span>
<span class="c"># New jobs per/sec: 380.4</span>
<span class="c"># Jobs processed per/sec: 10.0</span>


</code></pre>
<p>There are two types of inspection:</p>

<ul>
<li>inspect:status - returns the current amount of jobs/tasks in your queue 
and basic information about the speed (not very accurate)</li>
<li>inspect:monitor - returns the amount of jobs added and processed per sec. 
It&#39;s accurate, but works only for the redis (so far)</li>
</ul>
<h2 id='shell'>Shell</h2><pre class="highlight shell"><code>python manage.py shell
</code></pre><pre class="highlight python tab-python"><code>
<span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">get_project</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">get_project</span><span class="p">()</span><span class="o">.</span><span class="n">get_app</span><span class="p">(</span><span class="s">"hacker_news"</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="o">&lt;</span><span class="n">stairs</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="n">App</span> <span class="n">at</span> <span class="mh">0x105fa7d30</span><span class="o">&gt;</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="n">get_project</span><span class="p">()</span><span class="o">.</span><span class="n">get_app</span><span class="p">(</span><span class="s">"hacker_news"</span><span class="p">)</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">producers</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span>
<span class="p">{</span><span class="s">'read_google_big_table'</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">stairs</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">producer</span><span class="o">.</span><span class="n">Producer</span> <span class="n">at</span> <span class="mh">0x1257c4828</span><span class="o">&gt;</span><span class="p">}</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="n">producer</span> <span class="o">=</span> <span class="n">get_project</span><span class="p">()</span><span class="o">.</span><span class="n">get_app</span><span class="p">(</span><span class="s">"hacker_news"</span><span class="p">)</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">producers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"read_google_big_table"</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">5</span><span class="p">]:</span> <span class="n">producer</span><span class="o">.</span><span class="n">process</span><span class="p">()</span>

</code></pre>
<p>It&#39;s possible to run all producers, pipelines, consumers using ipython.</p>
<h2 id='change-the-queue-streaming-server'>Change the queue/streaming server</h2><pre class="highlight python tab-python"><code><span class="c"># in manage.py </span>

<span class="kn">from</span> <span class="nn">stepist</span> <span class="kn">import</span> <span class="n">App</span>
<span class="kn">from</span> <span class="nn">stairs.services.management</span> <span class="kn">import</span> <span class="n">init_cli</span>
<span class="kn">from</span> <span class="nn">stairs.core.project</span> <span class="kn">import</span> <span class="n">StairsProject</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">stepist_app</span> <span class="o">=</span> <span class="n">App</span><span class="p">()</span>
    <span class="n">celery</span> <span class="o">=</span> <span class="n">Celery</span><span class="p">(</span><span class="n">broker</span><span class="o">=</span><span class="s">"redis://localhost:6379/0"</span><span class="p">)</span>
    <span class="n">app</span><span class="o">.</span><span class="n">worker_engine</span> <span class="o">=</span> <span class="n">CeleryAdapter</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="n">celery</span><span class="p">)</span>

    <span class="n">stairs_project</span> <span class="o">=</span> <span class="n">StairsProject</span><span class="p">(</span><span class="n">stepist_app</span><span class="o">=</span><span class="n">stepist_app</span><span class="p">)</span>
    <span class="n">stairs_project</span><span class="o">.</span><span class="n">load_config_from_file</span><span class="p">(</span><span class="s">"config.py"</span><span class="p">)</span>
    <span class="n">init_cli</span><span class="p">()</span>
</code></pre>
<p>Stairs is based completely on stepist. You can just define a new stepist app 
with a new &quot;broken&quot; engine and your stairs project is ready to go. </p>

<p><a href="https://github.com/electronick1/stepist">Stepist</a></p>
<h2 id='admin-panel'>Admin panel</h2><pre class="highlight shell"><code>python manage.py admin
</code></pre>
<p>It&#39;s a way to visualize all your pipelines, to see the status of queues and
information about each component of the pipeline.</p>

<p><img src="images/admin.png" alt="image" /></p>

<aside class="notice">
Under development
</aside>
<h1 id='faq'>FAQ</h1><h2 id='what-is-the-reason-behind-apps'>What is the reason behind apps?</h2><pre class="highlight python tab-python"><code>
<span class="c"># example of app config</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">App</span><span class="p">(</span><span class="s">"myapp"</span><span class="p">)</span>
<span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
    <span class="n">train_data_path</span><span class="o">=</span><span class="s">'/home/train.data'</span>
<span class="p">)</span>


<span class="c"># example of pipeline config</span>

<span class="n">pipeline_config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">cleanup_flow</span><span class="o">=</span><span class="n">CleanUpText</span><span class="p">())</span>

<span class="nd">@app.pieline</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">external_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cleanup_flow</span><span class="p">)</span>

<span class="c"># in some other app, you can now make like this:</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">cleanup_flow</span><span class="o">=</span><span class="n">MYCleanup</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_pipeline</span><span class="p">(</span><span class="n">external_pipeline</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="c"># And it ^ will be executed with your "clean up" flow </span>

</code></pre>
<p>The main idea is to simplify process of reusing external solutions.</p>

<p>The Data-Science world is non-standardized right now, and stairs is 
trying to create the enviroment where reusing someone&#39;s approach will 
be easy and scalable for you. </p>

<p>For example, each app and pipeline has a config. App config allows you to set 
different config variables to external apps (inside your app/project). Pipelines
config allows you to redefine certain components of the pipeline or change any
logic you want. </p>

<p>A good example of configs is <a href="https://github.com/electronick1/stairs_examples/blob/master/bag_of_words/word2vec/app_config.py">here</a> 
or <a href="https://github.com/electronick1/stairs_examples/blob/master/bag_of_words/word2vec/pipelines.py#L13">here</a></p>
<h2 id='why-does-the-pipeline-builder-use-quot-mocked-quot-data'>Why does the pipeline builder use &quot;mocked&quot; data ?</h2>
<p>The pipeline builder <code>app.pipeline()</code> exists only to create a pipeline,
to configure it, and return the &quot;Worker&quot; object which then will be executed
by using a streaming/queue service. </p>

<p>At the moment we are building a pipeline, we know nothing about 
real data. Due to this fact, we use certain mock objects. When you run the producer,
it will populate these &#39;mock&#39; objects, and the components of the pipeline 
will work with real data.</p>
<h2 id='what-data-should-return-each-component-of-the-pipeline'>What data should return each component of the pipeline?</h2>
<p>Except the &quot;flow_producer&quot;/&quot;func_producer&quot;, all components must return <code>dict</code> 
as a result. Where we have key:value defined.</p>

<p>Right now stairs supports redis (internal implementation), RMQ and SQS services.</p>

<p>It&#39;s used for combining &quot;real&quot; data with &quot;mock&quot; values. </p>

<p>Right now some experiments ongoing with Kafka.</p>
<h2 id='python-async'>Python async</h2>
<p>One of the greatest thing about data pipelines is an easy way to scale each step,
without influence on others. This could be a great opportunity to use async paradigm
for some pipelines/steps.</p>

<p>Async (asyncio) it&#39;s quite powerful tool which helps on solving a lot of task,
in stairs it will be possible to use it only when needed.</p>

<p>You can define pipeline which should be run in a &quot;async&quot; mode:</p>
<pre class="highlight python tab-python"><code><span class="nd">@async_pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">MyFlow</span><span class="p">())</span>

  <span class="c"># connect none-async pipeline</span>
  <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">subscribe_pipeline</span><span class="p">(</span><span class="n">none_async_pipeline</span><span class="p">())</span>

</code></pre>
<p>For example, if you define <code>async_pipeline</code> all steps inside could be run in
&quot;async&quot; mode, and you can still connect regular (none-async) pipelines inside</p>
<h2 id='quot-speed-and-power-quot-c-clarkson'>&quot;Speed and Power&quot; (c) Clarkson</h2>
<p><a href="https://youtu.be/KB3RAGSi62c?t=14">Like Clarkson</a> Stairs is also believe in
Speed and Power. One of the main focus is to make stairs as much faster as possible
so you can process any amount of data you want.  </p>

      </div>
      <div class="dark-box">
          <div class="lang-selector">
                <a href="#" data-language-name="python">python</a>
          </div>
        <img src="images/stairs.png" class="stairs" alt="Stairs" />
        <#= image_tag 'data_pipeline.png', class: 'data_pipeline' %>
        <#= image_tag 'parallel.png', class: 'parallel' %>
        <#= image_tag 'ds_en.png', class: 'ds_en' %>
        <#= image_tag 'project_structure.png', class: 'project_structure' %>
        <#= image_tag 'app.png', class: 'app' %>
      </div>
    </div>
  </body>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134422072-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134422072-1');
  </script>

</html>
