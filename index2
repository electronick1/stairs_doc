<h1 id='welcome'>Welcome</h1>
<p>Stairs is a simple tool which allows you to divide your data into parts and make it understandable. </p>

<p>You can build data pipelines, draw parallels and make async or distributed calculations for most of your data related tasks.</p>

<p>Stairs is available in Python3, but you can write data processors in any language. 
You can also use any of streaming or queue services.</p>

<p>It&#39;s easy to start. Quickly test all your ideas or hypotheses and everything is 
ready for immediate use without any special magic. </p>

<p>Start with &quot;Installation&quot; and then proceed on to &quot;Getting started&quot;. </p>
<h1 id='installation'>Installation</h1><pre class="highlight python tab-python"><code><span class="c"># install redis https://redis.io/topics/quickstart</span>
<span class="c"># sudo apt-get install redis</span>
<span class="c"># brew install redis</span>

<span class="n">pip</span> <span class="n">install</span> <span class="n">stairs</span><span class="o">-</span><span class="n">project</span>
</code></pre>
<blockquote>
<p>It&#39;s recommended to use the latest python 3 version.</p>
</blockquote>

<p>Just perform <code>pip install stairs-project</code> to install stairs along with all 
python dependencies.</p>

<p>Stairs requires Redis for storing statistics and some meta-information, 
even if you use different streaming or queue service. </p>

<aside class="notice">
A running Redis server is requered for Stairs to work. 
</aside>
<h1 id='mission'>Mission</h1><h2 id='data-pipelines'>Data Pipelines</h2>
<!-- > ![image](images/data_pipeline.png) -->

<p>The main focus of Stairs is data pipelines. It&#39;s a framework which helps you to
build and manipulate data with the help of a data flow graph. </p>

<p>You can think of it as an MVP framework (like Django) for data pipelines.
Different layers of abstractions and components allow you to build any kind of 
data flow graphs and easily understand what&#39;s going on in your system. </p>
<h2 id='parallel-async-distributed'>Parallel/Async/Distributed</h2>
<!-- > ![parallel](images/parallel.png) -->

<p>Each component of a data pipeline can be represented as a separate python 
process (worker). Components communicate with each other by using 
streaming/queue services and together they can process your data in a parallel way.</p>

<p>Right now Stairs is using: <br>
- celery <br>
- self-implemented redis queue <br>
- kafka (under development) <br></p>

<p>There is an interesting article about workers/jobs on wiki
-&gt; <a href="https://en.wikipedia.org/wiki/Job_(computing)">Wiki</a></p>

<p>The Stairs framework focuses on speed and light, and the speed 
of your &quot;workers&quot; is limited mostly by your streaming/queue service.</p>
<h2 id='for-data-science-and-data-engineering-with-love'>For data-science and data-engineering with love</h2>
<!-- > ![ds_en](images/ds_en.svg) -->

<p>Data-science and data-engineering are growing fast, and it&#39;s hard 
to be an expert in everything at the same time. </p>

<p>For example, to train ML models, you should spend about 80% of your time 
to process data -- how fast you are able to process your data and test 
all hypotheses will influence your final result.</p>

<p>Stairs allows a data scientist to build &quot;scalable&quot; solutions without 
a high level of data-engineering skills.</p>

<ul>
<li>A data-scientist can focus only on data processing</li>
<li>A data-engineer can focus only on storing and moving data 
(between pipeline components)</li>
</ul>
<h1 id='getting-started'>Getting started</h1><h2 id='project'>Project</h2><pre class="highlight shell tab-shell"><code>stairs-admin project:new name
</code></pre>
<blockquote>
<p><img src="/images/project.svg" alt="project" /></p>
</blockquote>

<p>When you are done with installation, let&#39;s try kick-starting your first stairs project.</p>

<p>The Stairs project is similar to the django approach (when you can create a default 
project template). To have a better overview of your components you can create a
similar project with Stairs. It will consist of apps with all basic layers inside. <bt>
But you are completely free to use any other structure you want. The default 
project template is just a way to kick-start your idea quickly. </p>

<p>To create the default project template just use the following command:</p>

<p><code>stairs-admin project:new name</code></p>

<p>This command will generate a basic project structure with one app inside.<br></p>

<p>The project has a config file and &quot;manager.py&quot;.</p>

<p>&quot;manager.py&quot;  allows you to read a config, detect apps and 
execute shell commands in the Django manner.</p>

<p><br><br><br><br><br><br></p>
<h2 id='app'>App</h2><pre class="highlight shell tab-shell"><code>stairs-admin app:new name
</code></pre>
<blockquote>
<p><img src="/images/app.svg" alt="app" /></p>
</blockquote>

<p>The app is a way to generalize different approaches to one similar form. Why? 
Because right now data-science approaches are too scattered and it&#39;s hard to 
understand what&#39;s going on when there are tons of maths and algorithms around. </p>

<p>Each app has the following components:</p>

<ul>
<li><p>a pipeline - represents a data flow graph and shows how data 
will be processed. Each pipeline consists of multiple small components 
like &quot;Flow&quot; (Data flow).  </p></li>
<li><p>a producer - a function which helps you to read a source 
(a file, a database ...) and then directs it to the data pipeline.</p></li>
<li><p>a consumer - a function which writes data to the data store 
or changes &quot;global state&quot;.</p></li>
<li><p>a flow (Data Flow) - a set of functions 
(called <a href="https://en.wikipedia.org/wiki/Job_(computing)">steps</a>
which can change/filter/populate your data.</p></li>
</ul>

<p>To create a new &quot;default app&quot; structure (with package and modules) 
type the following command:</p>

<p><code>stairs-admin app:new name</code></p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">App</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">App</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"my_app"</span><span class="p">)</span>

</code></pre>
<p>To define your app you should initialize an App object with a name and a config 
(More about the app config in &quot;The App components&quot; section).
You can find this app object in the &quot;app_config.py&quot; file inside the default app. 
Don&#39;t forget to change its name. </p>

<p>If you want to add a new app to the project, populate 
<code>apps</code> variable in the config file or use <code>StairsProject().add_app(app)</code></p>

<p><br></p>

<p><img src="/images/app_2.svg" alt="image" /></p>

<p><br></p>
<h1 id='the-app-components'>The App components</h1><h2 id='pipeline'>Pipeline</h2><pre class="highlight python tab-python"><code>
<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">my_function_which_process_data</span><span class="p">,</span> <span class="n">as_worker</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> \
                <span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">MySecondFlow</span><span class="p">())</span>\
                <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_result</span><span class="p">)</span>

</code></pre>
<p>A pipeline is a way to combine multiple objects (functions/classes/other pipelines) in one big graph. </p>

<p>The way it works is a bit tricky but quite simple to understand. The input of each pipeline can be any data you want, then
you can subscribe some objects to these data, and add more and more objects to one big graph which is super easy to understand
and manipulate.</p>

<p>Each component of the pipeline can be a worker which communicates with other components through streaming/queue service.</p>

<p>To run a pipeline (and let data go through the components of the pipeline ) use: <br>
<code>python manager.py pipelines:run</code></p>

<p>It will run all workers and start to process your queue (using streaming/queue service).</p>

<p>If you want to run a particular pipeline, use the following command: <br>
<code>python manager.py pipelines:run app_name.pipeline_name</code> <br></p>

<p>Let&#39;s dive a bit deeper into the structure of pipelines:</p>

<p><br></p>

<p><img src="/images/pipeline_1.svg" alt="image" /></p>

<p><br><br></p>

<hr>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">full_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value1</span><span class="p">,</span> <span class="n">value2</span><span class="p">,</span> <span class="n">value3</span><span class="p">):</span>

    <span class="c"># DataFrame</span>
    <span class="n">all_at_once</span> <span class="o">=</span> <span class="n">concatinate</span><span class="p">(</span><span class="n">data_point1</span><span class="o">=</span><span class="n">value1</span><span class="p">,</span>
                              <span class="n">data_point2</span><span class="o">=</span><span class="n">value2</span><span class="p">,</span>
                              <span class="n">data_point3</span><span class="o">=</span><span class="n">value3</span><span class="p">)</span>

    <span class="c"># DataFrame</span>
    <span class="n">my_flow_result</span> <span class="o">=</span> <span class="n">all_at_once</span><span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">my_function</span><span class="p">,</span> <span class="n">as_worker</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c"># DataPoint</span>
    <span class="n">flow_data_point</span> <span class="o">=</span> <span class="n">my_flow_result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"result_data_point"</span><span class="p">)</span>

    <span class="c"># DataFrame</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">flow_data_point</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">MyFlow2</span><span class="p">())</span>\
                            <span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="n">flow2_result</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span>

<span class="nd">@app.pipeline</span>
<span class="k">def</span> <span class="nf">short_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value1</span><span class="p">,</span> <span class="n">value2</span><span class="p">,</span> <span class="n">value3</span><span class="p">):</span>

    <span class="c"># DataFrame</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">concatinate</span><span class="p">(</span><span class="n">data_point1</span><span class="o">=</span><span class="n">value1</span><span class="p">,</span> 
                         <span class="n">data_point2</span><span class="o">=</span><span class="n">value2</span><span class="p">,</span> 
                         <span class="n">data_point3</span><span class="o">=</span><span class="n">value3</span><span class="p">)</span>\
             <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">my_function</span><span class="p">,</span> <span class="n">as_worker</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>\
             <span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"result1"</span><span class="p">)</span>\
             <span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">MyFlow2</span><span class="p">())</span>\
             <span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="s">'result1'</span><span class="p">)</span>\

    <span class="k">return</span> <span class="n">result</span>

</code></pre><h3 id='manipulating-data-inside-the-pipeline'>Manipulating data inside the pipeline</h3>
<p>The input of the stairs pipeline is <a href="https://en.wikipedia.org/wiki/Mock_object">&quot;mock&quot;</a> values called &quot;DataPoint&quot;. It&#39;s a representation of the ANY data which will be performed inside the components of the pipeline. </p>

<p>The mock data will be converted into &quot;real&quot; data as soon as you call the pipeline: <br></p>

<p><code>short_pipeline(value1=1, value2=2, value3=3)</code> <br></p>

<p>But this &quot;real&quot; data will be accessible only inside the functions and flows which you have used in the subscribing methods.
(you can&#39;t use &quot;real&quot; values directly inside the pipeline function - this function is just for building pipelines, not for data manipulation)</p>

<p>You can subscribe to DataPoint with the help of some function or a Flow component and the result of this subscription will be a new object called &quot;DataFrame&quot; 
(a kind of dict object with a key: the DataPoint structure) - it represents the result of your flow.</p>

<p>You can subscribe to both DataPoint or DataFrame. But if you want to extract some values from DataFrame (the result of your flow) you can use the
<code>get(&#39;value&#39;)</code> method. The result of the &quot;get&quot; method will be DataPoint.</p>

<p>If you want to modify your DataFrame you can use the <code>make(value=new_value)</code> method and the result will be a new DataFrame.</p>

<p>Now the most interesting part: if you want to combine multiple DataPoints and DataFrame into one DataFrame you can use 
the <code>concatenate(value1=data_point, value2=data_point2)</code> function - which returns the DataFrame with defined arguments. </p>

<p>Here is an example of a pipeline -&gt; </p>

<p>As you can see, it&#39;s quite simple to define such complex and hard architecture just with 6 lines of code.
And it&#39;s a bit similar to how we define Neural Networks using <a href="https://keras.io/">Keras</a>.</p>

<p><br></p>

<p><img src="/images/pipeline_2.svg" alt="image" />
<br><br></p>

<hr>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">MyFlow</span><span class="p">(),</span> <span class="n">as_worker</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> \
                <span class="o">.</span><span class="n">apply_flow</span><span class="p">(</span><span class="n">MySecondFlow</span><span class="p">())</span>\
                <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_result</span><span class="p">)</span>

</code></pre><h3 id='how-the-pipeline-flow-changes-data'>How the pipeline flow changes data</h3>
<p>The components of the pipeline can accumulate data or completely change/redefine them. </p>

<p>For this stairs has two definitions: <br>
- subscribe_smths <br>
- apply_smths <br></p>

<p>to subscribe - to accumulate/update data <br>
to apply - to completely redefine data based on the pipeline component result. </p>

<p>Take into consideration that the result of each component is a dict object, which
&quot;accumulates&quot; by updating dict keys and values</p>

<p><br><br></p>

<p><img src="/images/pipeline_3.svg" alt="image" /></p>

<p><br></p>

<hr>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">base_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">BaseFlow</span><span class="p">(</span><span class="o">**</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span><span class="p">))</span>

<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_pipeline</span><span class="p">(</span><span class="n">base_pipeline</span><span class="p">)</span>\
                <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_result</span><span class="p">)</span>

<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">my_pipeline_with_config</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">use_lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_pipeline</span><span class="p">(</span><span class="n">base_pipeline</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>\
                <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_result</span><span class="p">)</span>

</code></pre><h3 id='call-another-pipeline'>Call another pipeline</h3>
<p>Each stairs pipeline is a worker which handles jobs in a separate process.<br>
You can use other pipelines inside the pipeline and send data between
them using queue/streaming service. </p>

<p>Note: you can&#39;t set the worker=False to the pipeline. </p>

<p>One of the core feature inside pipelines is a scalable way to configure them. 
The structure of the app and pipelines is quite friendly to configuration, 
you can set new config values and then call a new pipeline.</p>

<p><code>value.subscribe_pipeline(base_pipeline, config=dict(path=&#39;/home&#39;))</code></p>

<p>These values will be available inside <code>base_pipeline</code> as:</p>

<p><code>pipeline.config.get(&#39;path&#39;)</code></p>

<p><br><br><br><br><br><br><br><br><br><br><br></p>

<hr>
<pre class="highlight python tab-python"><code>
<span class="k">def</span> <span class="nf">custom_function</span><span class="p">(</span><span class="n">new_value</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">new_value</span><span class="o">=</span><span class="n">new_value</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>


<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">base_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span>\
        <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="k">lambda</span> <span class="n">value</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">new_value</span><span class="o">=</span><span class="n">value</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">'plus_one'</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">custom_function</span><span class="p">,</span> <span class="n">as_worker</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre><h3 id='subscribe-to-any-function-you-want'>Subscribe to any function you want</h3>
<p>It&#39;s possible to add any function to your data pipeline. </p>

<p>If you are using the lambda function, it&#39;s quite important to set a name, otherwise this function will be a worker and it will be impossible to recognize it. </p>

<p>Note: all these functions must return the <code>dict</code> object.</p>

<p><br><br><br><br><br><br><br><br><br><br><br></p>

<hr>
<pre class="highlight python tab-python"><code>
<span class="k">def</span> <span class="nf">custom_function</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">new_value</span><span class="o">=</span><span class="n">new_value</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>


<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">base_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span>\
        <span class="o">.</span><span class="n">subscribe_func</span><span class="p">(</span><span class="n">custom_function</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s">'/tmp/save_data.txt'</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">save_to_file</span><span class="p">,</span> <span class="n">as_worker</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre><h3 id='custom-values'>Custom values</h3>
<p>It&#39;s possible to add some additional values (with real data) into your pipeline. </p>

<p>It is useful if you want to configure something with constant variables or use the
pipeline config:</p>

<p><code>data.add_value(pipeline.config.get(&#39;url&#39;))</code></p>

<p><br><br><br><br><br><br><br><br><br><br><br></p>
<h2 id='flow'>Flow</h2><pre class="highlight python tab-python"><code><span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">)</span>
    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">first_step_result</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">first_step</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">first_step_result</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">second_step_result</span><span class="o">=</span><span class="n">first_step_result</span><span class="p">)</span>
</code></pre>
<p>The Flow is a low-level component which actually defines the data pipeline. </p>

<p>The problem with data pipelines builders is that it&#39;s not quite easy to 
change/redefine something, also, a great amount of functions
make pipelines like hell of dependencies (luigi good example of it). <br>
To solve these problems we have the FLOW component which can be used to: <br></p>

<ul>
<li>change/redefine/extend your pipeline easily (just use python inheritance)</li>
<li>configure easily</li>
<li>understand easily what&#39;s going on</li>
<li>each Flow can be a worker - the Flow has steps which should be run inside another worker</li>
</ul>

<p>The Flow represents a data flow graph as a chain of functions called &quot;steps&quot;. You can connect these steps simply by defining &quot;next step&quot; in the decorator:</p>

<p><code>@step(next_step, next_step ... )</code></p>

<p>The last step in your graph should be defined with the next step set to None.</p>

<p><code>@step(None)</code></p>

<p>All steps are executed in one &quot;worker&quot; (process).</p>

<p>The structure of the <code>Flow</code> class actually insperead by <a href="https://github.com/electoronick1/stepist">stepist</a></p>

<hr>
<pre class="highlight python tab-python"><code><span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">third_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">first_step_result</span><span class="p">,</span> <span class="n">second_step_result</span><span class="p">):</span>
        <span class="c"># which actually means value * 3</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">flow_result</span><span class="o">=</span><span class="n">value</span><span class="o">+</span><span class="n">first_step_result</span><span class="o">+</span><span class="n">second_step_result</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">third_step</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">first_step_result</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">second_step_result</span><span class="o">=</span><span class="n">first_step_result</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">first_step_result</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>    

</code></pre>
<p>The input for the next step the is the output from the current. </p>

<p>This idea is based on <a href="https://github.com/electronick1/stepist">stepist</a></p>

<p>The result of each step is accumulating, which means that from any low-level steps 
you will be able to get values from high-level steps.</p>

<p><br><br><br><br><br><br><br><br><br><br></p>

<hr>
<pre class="highlight python tab-python"><code><span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step_2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step_1</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step_1</span><span class="p">,</span> <span class="n">second_step_2</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c"># this step will be executed right after</span>
        <span class="c"># root1 and root2</span>
        <span class="c"># data from root1 and root2 will be merge into current step</span>
        <span class="k">pass</span>
</code></pre>
<p>You can define multiple &quot;next&quot; steps and this will allow you to build complex 
branchy pipelines, like in the example below -&gt;</p>

<p><img src="/images/flow1.svg" alt="image" />
<br><br><br><br><br></p>

<hr>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">FLow</span><span class="p">,</span> <span class="n">step</span>

<span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result_for_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_stats</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">result_for_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">calculate_stats</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result_for_2</span><span class="o">.</span><span class="n">validate_data</span><span class="o">.</span><span class="n">value</span> <span class="o">+</span> <span class="n">result_for_4</span><span class="o">.</span><span class="n">validate_data</span><span class="o">.</span><span class="n">value</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">validate_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">validate_data</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">calculate_stats</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">value</span> <span class="o">**</span> <span class="mi">2</span>

</code></pre>
<p>Now, to execute your flow class you should have the <code>__call__</code> method defined. </p>

<p>Inside the <code>__call__</code> you can execute any step from your flow. Then the whole chain 
(a pipeline) of steps will be executed. </p>

<p><code>self.mystep(**kwargs_for_highest_step)</code></p>

<p>or</p>

<p><code>self.start_from(self.mystep, **kwargs_for_highest_step)</code></p>

<p>As a result, you will get data from the last step in your pipeline (with the next_step set to None).</p>

<p><br><br><br><br><br><br><br><br><br><br><br></p>

<hr>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">FLow</span><span class="p">,</span> <span class="n">step</span>

<span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_from</span><span class="p">(</span><span class="n">first_step</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">first_step</span><span class="p">,</span> <span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">second_step</span><span class="p">}</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power3</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step</span><span class="p">,</span> <span class="n">save_result</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power2</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</code></pre>
<p>It&#39;s also possible to customize steps which should return the result data back. 
Just set the <code>save_result</code> flag to True. </p>

<p><br><br><br></p>

<p><img src="/images/flow2.svg" alt="image" /></p>

<p><br><br></p>

<hr>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">FLow</span><span class="p">,</span> <span class="n">step</span>

<span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_from</span><span class="p">(</span><span class="n">first_step</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">first_step</span><span class="p">,</span> <span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">second_step</span><span class="p">}</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power3</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step</span><span class="p">,</span> <span class="n">save_result</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power2</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MyFlow2</span><span class="p">(</span><span class="n">MyFlow</span><span class="p">):</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step</span><span class="p">,</span> <span class="n">save_result</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power4</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">4</span><span class="p">)</span>
</code></pre>
<p>The flow is a class, which means that we can use inheritance to redefine some steps logic.</p>

<p>It&#39;s a very powerful way to extend/change your data pipeline.</p>

<p><br><br></p>

<p><img src="/images/flow3.svg" alt="image" /></p>

<p><br><br><br><br><br><br></p>

<hr>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">FLow</span><span class="p">,</span> <span class="n">step</span>

<span class="k">class</span> <span class="nc">MyFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_from</span><span class="p">(</span><span class="n">first_step</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">first_step</span><span class="p">,</span> <span class="o">**</span><span class="n">result</span><span class="o">.</span><span class="n">second_step</span><span class="p">}</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power3</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="n">second_step</span><span class="p">,</span> <span class="n">save_result</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">first_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power2</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MyFlow2</span><span class="p">(</span><span class="n">MyFlow</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__reconect__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">second_step</span><span class="o">.</span><span class="n">set_next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">third_step</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">second_step</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="n">save_result</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="nd">@step</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">third_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">power4</span><span class="o">=</span><span class="n">value</span> <span class="o">**</span> <span class="mi">4</span><span class="p">)</span>
</code></pre>
<p>The inheritance also allows you to reconnect certain steps and change the Flow structure.</p>

<p>It&#39;s possible to add a new step to the top, insert it in the middle or add the &quot;save_result&quot; flag.</p>

<p><br><br></p>

<p><img src="/images/flow4.svg" alt="image" /></p>

<p><br><br></p>
<h2 id='producer'>Producer</h2>
<p>The producer is a set of components for reading any type of data and then call a pipeline to handle your data.</p>

<p>This component will populate your pipeline by &quot;real&quot; data which you can read from any source you want. </p>

<p>So far, we have two types of the producer&#39;s components: <br></p>

<ul>
<li>a simple iterator <br></li>
<li>a worker iterator - a way to read your data safely <br></li>
</ul>

<p>When you defined the producer, you can call it from the shell using manager.py:
<code>python manager.py producer:process</code></p>

<p><br><br></p>

<hr>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.producer</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">my_pipeline</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_file</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">FILE_PATH</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">row</span>

</code></pre><h3 id='simple-producer'>Simple Producer</h3>
<p>It&#39;s the function of the iterator which yields data to a pipeline. You can run this &quot;producer&quot; from the console:<br>
<code>python manager.py producer:process</code></p>

<p>It simply goes by all items, which the producer yields, and sends them to streaming/queue service which then goes to the pipeline. </p>

<p>To prevent overfitting of your streaming service you can set a &quot;limit&quot;. When the producer reaches this limit, it will sleep for a while. </p>

<p><br><br><br></p>

<hr>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.worker_producer</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">my_pipeline</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_database</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">AMOUNT_OF_ROWS</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">read_batch</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">read_batch</span><span class="p">(</span><span class="n">batch_id</span><span class="p">):</span>
    <span class="n">interval</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_id</span><span class="o">*</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_id</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s">"SELECT * FROM table where id&gt;</span><span class="si">%</span><span class="s">s and id&lt;</span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="n">interval</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">cursor</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">row</span>

</code></pre><h3 id='worker-producer'>Worker Producer</h3>
<p>It&#39;s a parallel/distributed way to populate your pipeline with data. It&#39;s almost 99% safe as it has smart features to prevent data loss or duplication.</p>

<p>The way it works is a bit more complicated then the way the simple producer works, but if you know something about &quot;batch&quot; processing, everything will be simple for you.</p>

<p>The idea is to split your data into batches and to read each batch independently. If the whole batch is read successfully, it goes to the pipeline. Internally, the worker producer
uses bitmaps to track the status of all your batches, and the only way you can lose your data is a fail with the redis.</p>

<p>The worker producer has two states: the first  is initializing. It just checks the number of batches and creates all necessary meta information. 
To initilaze the worker_producer run: <br>
<code>python manager.py producer:init</code></p>

<p>It must be executed only once.</p>

<p><br></p>

<p>To start reading the process you can run: <br>
<code>python manager.py producer:process</code></p>

<p>As it was mentioned earlier, the worker_producer is a parallel way to read your data. So, if you want more processes, just run the command above multiple times. 
It will read batches from the <code>producer:init</code> command.</p>

<p>It will prevent the queue from overfitting similar to the simple_producer. </p>

<p><br><br><br></p>
<h2 id='consumer'>Consumer</h2><pre class="highlight python tab-python"><code><span class="nd">@app.consumer</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">save_to_redis</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">):</span>
    <span class="n">redis</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
</code></pre>
<p>The consumer is a set of components for writing/saving your data to any type of store or changing the global state of your system.</p>

<p>You are free to write/save your data inside the Flow component, but the consumer is not only about saving. It is also a way to accumulate all
data to one place, and Stairs has 3 types of consumers:</p>

<ul>
<li>&quot;a simple consumer&quot; is a simple function which should not return any data. It&#39;s useful for saving data to the data store.</li>
<li>&quot;standalone_consumer&quot; is afunction which can be called as a separate process. It&#39;s useful for writing data to a file or accumulating them inside one process for something. </li>
<li>&quot;consumer_iter&quot; is afunction which yields data from the pipeline. It&#39;s useful when you want to train the neural network and needs data generator. </li>
</ul>

<p>Here on the right is an example of &quot;a simple consumer&quot; -&gt; 
<br><br></p>

<hr>
<pre class="highlight python tab-python"><code><span class="kn">import</span> <span class="nn">json</span>

<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">"file.txt"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span>

<span class="nd">@app.standalone_consumer</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">write_to_file</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">):</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

</code></pre>
<p>The Standalone consumer is a type of a consumer which will NOT execute automatically.</p>

<p>To execute it and process data inside, you need to run a special command:</p>

<p><code>python manager.py consumer:standalone app.write_to_file</code></p>

<p>It is useful when you need to write data using one process only (for example, in the case of file writing).</p>

<hr>
<pre class="highlight python tab-python"><code>
<span class="nd">@app.consumer_iter</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">x_data_for_nn</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="nd">@app.consumer_iter</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">y_data_for_nn</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">data</span>


<span class="c"># Example of pipeline</span>
<span class="nd">@app.pipeline</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">prepare_data_for_nn</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="n">result_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">Flow</span><span class="p">())</span>

    <span class="n">x_consumer</span> <span class="o">=</span> <span class="n">result_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'x'</span><span class="p">)</span>\
                            <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">x_data_for_nn</span><span class="p">)</span>
    <span class="n">y_consumer</span> <span class="o">=</span> <span class="n">result_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'y'</span><span class="p">)</span>\
                            <span class="o">.</span><span class="n">subscribe_consumer</span><span class="p">(</span><span class="n">y_data_for_nn</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">concatinate</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_consumer</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_consumer</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span>

<span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_data_for_nn</span><span class="p">(),</span>
                  <span class="n">y</span><span class="o">=</span><span class="n">y_data_for_nn</span><span class="p">())</span>


</code></pre>
<p>The Consumer as a separe process.</p>

<p>If you want to train the neural network and use the output of your pipeline as a train set, you can use:<br>
The <code>@consumer_iter()</code> component which allows you to read data from the streaming/queue service directly to your function.</p>
<h2 id='app-config'>APP Config</h2><pre class="highlight python tab-python"><code>
<span class="c"># app_config.py</span>

<span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">App</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">App</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"myapp"</span><span class="p">)</span>

<span class="n">app</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s">"use_validation"</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>

<span class="n">my_pipeline_config</span> <span class="o">=</span> <span class="p">{</span><span class="s">"validation_flow"</span><span class="p">:</span> <span class="n">ValidationFLow</span><span class="p">()}</span>

<span class="c"># pipelines.py</span>

<span class="nd">@app.pipeline</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">my_pipeline_config</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">validation_flow</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_validation</span><span class="p">:</span>
        <span class="n">result</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">ValidationFLow</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="c"># another project</span>

<span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_validation</span> <span class="o">=</span> <span class="bp">True</span>

</code></pre>
<p>It&#39;s a place where you can set up your app. </p>

<p>The App config allows defining app settings which are useful if you want to share your app with the world.</p>

<p>It&#39;s also possible to define the pipeline config as in the example -&gt; </p>

<p><br></p>
<h1 id='examples'>Examples</h1><h2 id='etl-example-hacker-news'>ETL example: hacker news</h2>
<p><a href="https://github.com/electronick1/stairs_examples/tree/master/hacker_news">github hacker_news</a><br></p>

<p>The idea here is to extract data from some source (in that case it&#39;s google cloud), to change them somehow and save them in a elegant format 
(for example, for making charts then or building neural networks).</p>

<p>You can start exploring this project from <code>producers.py</code> inside the hacker_new app. 
In this module it&#39;s quite insignificant where we read data, and what format we use as a result.</p>

<p>Then <code>pipelines.py</code> each producer will send data to pipelines, in our case we have two of them:<br>
- <code>cleanup_and_save_localy</code> - makes a basic text cleanup and filtering
- <code>calculate_stats</code> -  based on &quot;clean&quot; data, it calculates stats we need</p>

<p>The next (and the last) <code>consumers.py</code> - a place where all data come at the end of pipeline.</p>

<p><br></p>
<h2 id='ml-example-bag-of-words'>ML example: bag of words</h2>
<p><a href="https://github.com/electronick1/stairs_examples/tree/master/bag_of_words">github bag of words</a><br></p>

<p>Here we try teaching a neural network to solve <a href="https://www.kaggle.com/c/word2vec-nlp-tutorial">kaggle task &quot;Bag of Words Meets Bags of Popcorn&quot;</a></p>

<p>This example is based on <a href="https://github.com/wendykan/DeepLearningMovies/">this repo</a> And it&#39;s a kind of the copy-paste solution but for much better representation.</p>

<p>What does &quot;better representation&quot; mean? </p>

<p>If you look inside this repo, it&#39;s just a plain code. 
If you want to make calculations in a parrallel way it&#39;s not very trivial to do.
Also, if you want to change something, it&#39;s not easy to undestand all the changes of the data flow .</p>

<p>Stairs solves all these problems:</p>

<ul>
<li>It makes calculations in the parallel by default</li>
<li>You can easily understand what&#39;s going on inside the <code>pipelines.py</code></li>
<li>It is super easy to change something (just redefine certain methods in the FLow classes)</li>
</ul>
<h1 id='features'>Features</h1><h2 id='inspect-the-status-of-your-queues'>Inspect the status of your queues</h2><pre class="highlight shell"><code>python manager.py inspect:status app_name

<span class="c"># Queue: cleanup_and_save_localy</span>
<span class="c"># Amount of jobs: 10000</span>
<span class="c"># Queue decreasing by 101.0 tasks per/sec</span>


python manager.py inspect:monitor app_name

<span class="c"># Queue: cleanup_and_save_localy</span>
<span class="c"># Amount of jobs: 3812</span>
<span class="c"># New jobs per/sec: 380.4</span>
<span class="c"># Jobs processed per/sec: 10.0</span>


</code></pre>
<p>There are two types of inspection:</p>

<ul>
<li>inspect:status - returns the current amount of jobs/tasks in your queue and basic information about the speed (not very accurate)</li>
<li>inspect:monitor - returns the amount of jobs added and processed per sec. It&#39;s accurate, but works only for the redis (so far)</li>
</ul>
<h2 id='shell'>Shell</h2><pre class="highlight shell"><code>python manager.py shell
</code></pre><pre class="highlight python tab-python"><code>
<span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="kn">from</span> <span class="nn">stairs</span> <span class="kn">import</span> <span class="n">get_project</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">get_project</span><span class="p">()</span><span class="o">.</span><span class="n">get_app</span><span class="p">(</span><span class="s">"hacker_news"</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="o">&lt;</span><span class="n">stairs</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="n">App</span> <span class="n">at</span> <span class="mh">0x105fa7d30</span><span class="o">&gt;</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="n">get_project</span><span class="p">()</span><span class="o">.</span><span class="n">get_app</span><span class="p">(</span><span class="s">"hacker_news"</span><span class="p">)</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">producers</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span>
<span class="p">{</span><span class="s">'read_google_big_table'</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">stairs</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">producer</span><span class="o">.</span><span class="n">Producer</span> <span class="n">at</span> <span class="mh">0x1257c4828</span><span class="o">&gt;</span><span class="p">}</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="n">producer</span> <span class="o">=</span> <span class="n">get_project</span><span class="p">()</span><span class="o">.</span><span class="n">get_app</span><span class="p">(</span><span class="s">"hacker_news"</span><span class="p">)</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">producers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"read_google_big_table"</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">5</span><span class="p">]:</span> <span class="n">producer</span><span class="o">.</span><span class="n">process</span><span class="p">()</span>

</code></pre>
<p>It&#39;s possible to run all producers, pipelines, consumers using ipython.</p>
<h2 id='change-queue-streaming-server'>Change queue/streaming server</h2><pre class="highlight python tab-python"><code><span class="c"># in manager.py </span>

<span class="kn">from</span> <span class="nn">stepist</span> <span class="kn">import</span> <span class="n">App</span>
<span class="kn">from</span> <span class="nn">stairs.services.management</span> <span class="kn">import</span> <span class="n">init_cli</span>
<span class="kn">from</span> <span class="nn">stairs.core.project</span> <span class="kn">import</span> <span class="n">StairsProject</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">stepist_app</span> <span class="o">=</span> <span class="n">App</span><span class="p">()</span>
    <span class="n">celery</span> <span class="o">=</span> <span class="n">Celery</span><span class="p">(</span><span class="n">broker</span><span class="o">=</span><span class="s">"redis://localhost:6379/0"</span><span class="p">)</span>
    <span class="n">app</span><span class="o">.</span><span class="n">worker_engine</span> <span class="o">=</span> <span class="n">CeleryAdapter</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="n">celery</span><span class="p">)</span>

    <span class="n">stairs_project</span> <span class="o">=</span> <span class="n">StairsProject</span><span class="p">(</span><span class="n">stepist_app</span><span class="o">=</span><span class="n">stepist_app</span><span class="p">)</span>
    <span class="n">stairs_project</span><span class="o">.</span><span class="n">load_config_from_file</span><span class="p">(</span><span class="s">"config.py"</span><span class="p">)</span>
    <span class="n">init_cli</span><span class="p">()</span>
</code></pre>
<p>Stairs is based completely on stepist. You can just define a new stepist app with a new &quot;broken&quot; engine, 
and your stairs project is ready to go </p>

<p><a href="https://github.com/electronick1/stepist">Stepist</a></p>
<h2 id='admin-panel'>Admin panel</h2><pre class="highlight shell"><code>python manager.py admin
</code></pre>
<p>It&#39;s a way to visualize all your pipelines, to see the status of queues and information about each component of the pipeline.</p>

<p><img src="/images/admin.png" alt="image" /></p>

<aside class="notice">
Under development
</aside>
<h1 id='faq'>FAQ</h1><h2 id='what-is-the-reason-behind-apps'>What is the reason behind apps?</h2><pre class="highlight python tab-python"><code>
<span class="c"># example of app config</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">App</span><span class="p">(</span><span class="s">"myapp"</span><span class="p">)</span>
<span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
    <span class="n">train_data_path</span><span class="o">=</span><span class="s">'/home/train.data'</span>
<span class="p">)</span>


<span class="c"># example of pipeline config</span>

<span class="n">pipeline_config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">cleanup_flow</span><span class="o">=</span><span class="n">CleanUpText</span><span class="p">())</span>

<span class="nd">@app.pieline</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">external_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_flow</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cleanup_flow</span><span class="p">)</span>

<span class="c"># in some other app, you can now make like this:</span>
<span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">cleanup_flow</span><span class="o">=</span><span class="n">MYCleanup</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">subscribe_pipeline</span><span class="p">(</span><span class="n">external_pipeline</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="c"># And it ^ will be executed with your "clean up" flow </span>

</code></pre>
<p>The main idea is to simplify reusing external solutions.</p>

<p>The Data-Science world is non-standardized right now, and stairs is trying to create the enviroment
where reusing someone&#39;s approach will be easy and scalable for you. </p>

<p>For example, each app has a config. It allows you to set different config variables to external apps (inside your app/project).</p>

<p>Each pipeline has a config. It allows you to redefine certain components of the pipeline or change any logic you want. </p>

<p>A good example of configs is <a href="https://github.com/electronick1/stairs_examples/blob/master/bag_of_words/word2vec/app_config.py">here</a> 
or <a href="https://github.com/electronick1/stairs_examples/blob/master/bag_of_words/word2vec/pipelines.py#L13">here</a></p>
<h2 id='why-does-the-pipeline-builder-use-quot-mocked-quot-data'>Why does the pipeline builder use &quot;mocked&quot; data ?</h2>
<p>The pipeline builder <code>app.pipeline()</code> exists only to create a pipeline, to configure it, 
and return the &quot;Worker&quot; object which then will be executed by using streaming/queue service.c </p>

<p>At the moment we are building a pipeline, we don&#39;t know anything about real data which comes to it later, 
so that&#39;s why we aggeread on some mock values and then populate this &quot;mock&quot; values from producer (or other pipeline).</p>
<h2 id='what-should-data-return-to-each-component-of-the-pipeline'>What should data return to each component of the pipeline?</h2>
<p>Except the &quot;flow_generator&quot;, all components must return <code>dict</code> as format. Where we have key:value defined.</p>

<p>It&#39;s used for combining &quot;real&quot; data with &quot;mock&quot; values. </p>
